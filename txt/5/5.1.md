## 5.1 Hive介绍

&emsp;&emsp;简单来说，Hive是一个构建在Hadoop上的数据仓库工具（框架），擅长OLAP（联机分析处理）。其可以将结构化的数据文件映射成一张数据表，并可以使用类SQL的方式来对这样的数据文件进行读，写以及管理（包括元数据）。这套Hive SQL 简称HQL。几乎所有的Hadoop环境都会配置Hive的应用，虽然Hive易用，但其查询性能并不算优秀，在后续的内容我们会说明这点。在本节中，我们主要是简要介绍一下Hive的框架等内容，Hive的重点会侧重在具体的操作上，也就是下一节的内容。

### 5.1.1 什么是OLAP？

&emsp;&emsp;我们刚刚提到，Hive删除OLAP，那么什么是OLAP呢？

&emsp;&emsp;OLAP 全称是 Online Analytical Processing（联机分析处理）。它是一种专门用于支持复杂数据分析、查询和报表生成的技术。OLAP 与 OLTP（联机事务处理）相对，后者专注于高效事务处理（比如银行转账、电商下单），常见的OLAP包括Hive等，而常见的OLTP的代表则是大家耳熟能详的MySQL。简单来说，OLAP 面向“分析”，OLTP 面向“事务”。

&emsp;&emsp;OLAP 的核心特点如下：

* 多维数据分析：OLAP 支持以多维方式对数据进行查询分析，比如按照时间、地区、产品等维度聚合数据。
* 大规模数据汇总：OLAP 能够快速计算大量数据（比如计算销售总额、平均值、同比环比）。
* 高响应速度：通过预计算、索引和专门优化，OLAP 系统能实现亚秒级甚至毫秒级的查询响应。
* 面向决策支持：OLAP 主要用于生成 BI（商业智能）报表、仪表盘、数据洞察分析等决策支持场景。


| 特点   | OLAP                        | OLTP                       |
| ---- | --------------------------- | -------------------------- |
| 主要目的 | 支持分析和决策                     | 支持日常事务处理                   |
| 操作类型 | 查询为主（SELECT），少写入            | 读写均衡（INSERT、UPDATE、DELETE） |
| 数据规模 | 海量历史数据（TB\~PB）              | 实时数据、当前活跃数据（GB\~TB）        |
| 响应速度 | 对大批量数据进行快速聚合计算              | 对单条记录进行快速更新或查询             |
| 架构设计 | 多维数据模型（星型、雪花模型）             | 关系型模型（ER 模型）               |
| 示例   | Hive、ClickHouse、Kylin、Doris | MySQL、PostgreSQL、MongoDB   |



### 5.1.2 Hive的历史

&emsp;&emsp;Hive在2008年面世，最初由Facebook开发的，目的是为了解决存储在Hadoop中的大量数据的查询和分析问题。Facebook的工程师希望能让非计算机专业的用户也能通过简单的SQL语言进行数据操作。在2024年发布了最新的4.0版本，并宣布3.X版本生命周期结束（End of Life, EOL）。注意在4.0版本中不再支持使用Spark引擎（Hive on Spark）。官方说明如下：

>"Apache Hive 4.0 has removed the support for Spark as an execution engine. Hive-on-Spark has been deprecated and removed."

### 5.1.3 Hive架构

<p align="center">
    <img src="/pic/5/5-2 Hive架构图.png" width="50%">
    <br/>
    <em>图5-2 Hive架构图</em>
</p>

&emsp;&emsp;我们知道，Hive提供了使用SQL语句来查询、分析HDFS集群中结构化数据的能力，（你可以理解为Hive能够支持在HDFS集群中创建关系型数据库）那么在这个过程中我们面临着以下几个问题：

* SQL语句如何转换为能被HDFS集群中数据所能接收的操作，因为本质上原生HDFS并不支持SQL。
* Hive所构造的表数据如何存放，这涉及到两部分，一部分是维护表中的数据，另一部分是维护表示表结构的数据，也即元数据。
* 我们如何访问Hive来提交任务。

&emsp;&emsp;我们结合图5-2 Hive的架构图来一个个来回答这些问题。

&emsp;&emsp;首先在Hive中存在一个组件Driver，在其内部包括了解析器（Parser）、编译器（Complier）、优化器（Optimizer）、执行器（Executor），通过解析->编译->优化->执行四个步骤，将HQL语句转换为MapReduce任务最终与Yarn集群的ResourceManager交互完成任务。所以Hive的SQL查询最终是基于MapReduce批处理引擎来实现的，这也是在本节的一开始所说其性能并不算优秀的原因，因为其归根结底会被翻译为MapReduce任务，查询的速度是比不上传统的关系型数据库如MySQL。当然，在目前Hive也支持将HQL翻译为Spark或是Tez（也是一个分布式计算框架）程序并且也提倡使用者如此做，因为这能大大提高查询、分析的性能。

&emsp;&emsp;Hive在启动时会自动检测Hadoop环境，一旦检测到安装了Hadoop，则会将Hive中的各种表实际数据以Block的形式存放在HDFS集群中，Hive也可以单机运行，数据存储在本地的文件系统，本书不考虑单机运行的情况，因为这多用于个人测试；元数据的存放方式和Hive的运行模式有关，Hive有三种运行模式：

1. 内嵌模式（Embedded Mode）：使用内嵌的Derby数据库存储元数据，无需独立数据库服务。但如此做仅支持单会话访问，多用户同时操作会报错，因此只适用于快速测试或单用户实验环境，不适用于生产环境。
2. 本地模式（Local Mode）：使用本地外部数据库（如MySQL、PostgreSQL）替代Derby存储元数据，支持多用户访问，适合小规模多用户开发环境。
3. 远程模式（Remote Mode）：元数据存储于远端的独立的外部数据库，客户端通过Thrift协议连接远程Metastore服务，支持高并发访问，是生产环境首选，支持分布式集群和大规模并发访问。

&emsp;&emsp;总的来说，元数据的存储要么在Hive内置的Derby数据库，要么存储于外部的SQL数据库。那为什么不将元数据直接存储在对应的HDFS集群中呢？这样做应该会更方便更简单，这主要是基于几个方面的考虑：

1. 元数据（如表的定义、列信息、分区、文件位置等）在查询时需要频繁访问，而SQL数据库通常提供优化的索引、查询缓存和事务支持，使得对元数据的读取和修改更高效。相比之下，HDFS是为大数据存储和批处理设计的，虽然可以用来存储大量数据，但它在处理小文件和频繁的小规模读取时并不高效。
2. Hive的设计思想之一是将查询语言（HiveQL）与底层存储引擎（如HDFS）解耦，如此做当我们更换底层的分布式文件系统时导致的兼容性问题就会少许多。

&emsp;&emsp;第三个问题，我们如何访问Hive，如架构图所示，客户主要通过Hive提供的各种API接口来访问Hive，提供了ODBC（基于C语言的通用数据库接口）和JDBC（专为JAVA设计的API），以及命令行接口Beeline，在之前还提供Hive CLI，不过目前已被弃用。Beeline需要和HiveServer2配合使用，在服务器端要启动HiveServer2服务，客户端使用Beeline连接，同时Hive也提供了WebGUI接口。

&emsp;&emsp;回答完了所有问题，我们来过一遍Hive执行HQL语句的过程，首先客户通过JDBC等API提交HQL语句，Hive通过Driver将语句翻译为MapReduce作业（默认情况）或是Spark、Tez程序。接着结合元数据信息（内嵌在Derby数据库或是来自外部SQL数据库）操作HDFS集群中数据，最终返回结果。


### 5.1.4 总结

&emsp;&emsp;本章我们简单介绍了Hive的框架以及HQL语句执行的过程，在下个小节中我们会亲自动手部署一个Hive并学习其的诸多操作，说的多不如练的多，在实际操作中我们会进一步讲解Hive有关的各种知识。
