## 5.2 Hive实践

&emsp;&emsp;在本章中，我们将会进行Hive的安装、操作等相关内容的讲解，请确保你已完成了HDFS、ZooKeeper、Yarn三者的配置，并确认Yarn集群能正常执行MapReduce任务。

## 5.2.1 Hive安装

&emsp;&emsp;在本书中，由于广泛使用的Hive3.X版本的生命周期已结束，为保证兼容性，综合考虑下采用Hive4.0.0版本完成实验，在Hive4中完全禁用了Hive CLI，故整个的配置过程与网络上流行的教程有比较大不同。由于本书的环境属于小规模的集群，所以选择的运行模式为本地模式（Local Mode），这意味着我们还需要在本地安装SQL数据库，在本书中选用的是MySQL。安装过程需要做的工作大致如下：

1. 安装MySQL
2. 修改Hadoop配置环境以适配Hive
3. 安装Hive
4. 修改Hive配置环境
5. 连接MySQL，初始化元数据
6. 写下我们的第一条HQL语句
   
**（1） 安装MySQL**

&emsp;&emsp;在`m1`上安装MySQL服务端以及客户端。

```shell
sudo apt-get install mysql-server
sudo apt-get install mysql-client
```

&emsp;&emsp;安装完成后，MySQL应该已经默认启动，可以使用命令`service mysql status`查看状态，显示 active（running）证明MySQL正常运行。

```shell
root@m1:~# service mysql status
● mysql.service - MySQL Community Server
     Loaded: loaded (/usr/lib/systemd/system/mysql.service; enabled; preset: enabled)
     Active: active (running) since Wed 2025-05-28 15:13:53 CST; 27min ago
    Process: 1013 ExecStartPre=/usr/share/mysql/mysql-systemd-start pre (code=exited, status=0/SUCCESS)
   Main PID: 1221 (mysqld)
     Status: "Server is operational"
      Tasks: 37 (limit: 4006)
     Memory: 430.9M (peak: 441.0M)
        CPU: 2.891s
     CGroup: /system.slice/mysql.service
             └─1221 /usr/sbin/mysqld

May 28 15:13:52 m1 systemd[1]: Starting mysql.service - MySQL Community Server...
May 28 15:13:53 m1 systemd[1]: Started mysql.service - MySQL Community Server.

```

&emsp;&emsp;MySQL的超级用户root默认未设置密码，使用命令`sudo mysql -u root`登录。并使用`select version();`查看版本。

```shell
root@m1:~# sudo mysql -u root
Welcome to the MySQL monitor.  Commands end with ; or \g.
Your MySQL connection id is 13
Server version: 8.0.42-0ubuntu0.24.04.1 (Ubuntu)

Copyright (c) 2000, 2025, Oracle and/or its affiliates.

Oracle is a registered trademark of Oracle Corporation and/or its
affiliates. Other names may be trademarks of their respective
owners.

Type 'help;' or '\h' for help. Type '\c' to clear the current input statement.

mysql> select version();
+-------------------------+
| version()               |
+-------------------------+
| 8.0.42-0ubuntu0.24.04.1 |
+-------------------------+
1 row in set (0.00 sec)
```

&emsp;&emsp;由于Linux下MySQL的默认root用户认证方式使用`auth_socket`，而Hive可能不支持，故我们需更改认证方式并设定密码，最后刷新更改。

```
ALTER USER 'root'@'localhost' IDENTIFIED WITH mysql_native_password BY 'yourpassword';
FLUSH PRIVILEGES;
```

&emsp;&emsp;最后退出MySQL并重启MySQL服务。

```
mysql> exit;
Bye
root@m1:~# sudo systemctl restart mysql
```

**（2） 修改Hadoop配置环境以适配Hive**

&emsp;&emsp;在这步中，我们需要修改的配置文件`core-site.xml`。其在hadoop根目录下的`/etc/hadoop`文件夹中，在配置文件中新增：

```xml
    <property>
        <name>hadoop.proxyuser.root.hosts</name>
        <value>*</value>  <!-- 允许来自任何主机的 root 用户代理 -->
    </property>
    <property>
        <name>hadoop.proxyuser.root.groups</name>
        <value>*</value>  <!-- 允许 root 代理任何用户组的用户 -->
    </property>

```

&emsp;&emsp;同时，在HDFS中创建Hive保存数据所需文件夹：

```shell
hdfs dfs -mkdir -p /user/hive/warehouse 
hdfs dfs -mkdir -p /tmp/hive/ 
hdfs dfs -chmod 750 /user/hive/warehouse 
hdfs dfs -chmod 777 /tmp/hive
```

**（3） 安装Hive**

&emsp;&emsp;下载Hive4.0.0到root目录下，并解压，为统一命名将其命名为`hive-4.0.0`。

```shell
wget https://archive.apache.org/dist/hive/hive-4.0.0/apache-hive-4.0.0-bin.tar.gz
tar -zxvf apache-hive-4.0.0-bin.tar.gz
mv apache-hive-4.0.0-bin hive-4.0.0
```

&emsp;&emsp;之后配置环境变量，编辑`/etc/profile`，在文件末尾添加如下内容，之后使用命令`source /etc/profile`激活环境变量。

```
export HIVE_HOME=/root/hive-4.0.0
export PATH=$PATH:$HIVE_HOME/bin
```

&emsp;&emsp;输入命令`hive version`，出现以下内容说明安装成功。

```shell
root@m1:~# hive version
Beeline version 4.0.0 by Apache Hive
```

&emsp;&emsp;如果出现如下关于SLF4j的警告，这是因为HBase，Hadoop和Hive都有自己内置的SLF4j（这是一个日志管理组件）库，绑定了多个版本导致的，不影响程序正常运行。

```
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/root/hive-4.0.0...]
SLF4J: Found binding in [jar:file:/root/hadoop-3.3.6...]
SLF4J: Actual binding is of type [org.apache...]
SLF4J: Class path contains multiple SLF4J bindings.
```

**（3） 安装Hive**

&emsp;&emsp;我们需要修改的配置文件均位于`hive-4.0.0/conf`下，在该目录下我们新建两个文件：
* `hive-site.xml`
* `hive-env.sh`

&emsp;&emsp;`hive-site.xml`填入以下内容：

```shell
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<configuration>
  <property>
    <name>javax.jdo.option.ConnectionURL</name>
    <value>jdbc:mysql://localhost:3306/hive?createDatabaseIfNotExist=true</value>
    <description>Metadata store connection URL</description>
  </property>
  <property>
    <name>javax.jdo.option.ConnectionDriverName</name>
    <value>com.mysql.cj.jdbc.Driver</value>
    <description>Metadata store JDBC driver</description>
  </property>
  <property>
  <!-- 连接用户名，本书为root -->
    <name>javax.jdo.option.ConnectionUserName</name>
    <value>root</value>
    <description>Metadata store username</description>
  </property>
  <property>
  <!-- 这里修改为上一步mysql中设置的密码 -->
    <name>javax.jdo.option.ConnectionPassword</name>
    <value>yourpassword</value>
    <description>Metadata store password</description>
  </property>
  <!-- hive默认在hdfs的工作目录 -->
  <property>
    <name>hive.metastore.warehouse.dir</name>
    <value>/user/hive/warehouse</value>
  </property>
  <!-- 指定hiveserver2连接的host -->
  <property>
    <name>hive.server2.thrift.bind.host</name>
    <value>m1</value>
  </property>
  <!-- 指定hiveserver2连接的端口号 -->
  <property>
    <name>hive.server2.thrift.port</name>
    <value>10000</value>
  </property>
  <property>
    <name>hive.metastore.uris</name>
    <value>thrift://localhost:9083</value>
  </property>
  <!-- hiveserver2的高可用参数，如果不开会导致了开启tez session导致hiveserver2无法启动 -->
  <property>
    <name>hive.server2.active.passive.ha.enable</name>
    <value>true</value>
  </property>
  <!--解决Error initializing notification event poll问题-->
  <property>
    <name>hive.metastore.event.db.notification.api.auth</name>
    <value>false</value>
  </property>
  <property>
    <name>hive.server2.enable.doAs</name>
    <value>false</value>  <!-- 启用用户代理 -->
  </property>
</configuration>

```

&emsp;&emsp;`hive-env.sh`填入以下内容，注意各个环境变量应设置为读者机器中对应的路径。

```sh
export HIVE_CONF_DIR=/root/hive-4.0.0/conf
export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64
export HADOOP_HOME=/root/hadoop-3.3.6
export HIVE_AUX_JARS_PATH=/root/hive-3.3.6/lib
```

&emsp;&emsp;接下来下载MySQL驱动Jar包，如果使用该数据库作为元数据存储位置，需要使得Hive能够连接到数据库，因此需要在lib目录下放入驱动jar包，可以使用wget直接下载。注意该文件需放入`hive-4.0.0/lib`目录下。

&emsp;&emsp;`wget https://repo1.maven.org/maven2/com/mysql/mysql-connector-j/8.0.32/mysql-connector-j-8.0.32.jar`

**（5） 连接MySQL，初始化元数据**

&emsp;&emsp;首先执行初始化Hive元数据。

&emsp;&emsp;`schematool -initSchema -dbType mysql`

&emsp;&emsp;等待，直到输出`Initialization script completed`则为初始化成功。

&emsp;&emsp;随后依次启动ZooKeeper集群、HDFS集群和Yarn集群。

```
start-dfs.sh
start-yarn.sh
```

&emsp;&emsp;接着启动HiveServer2和metastore服务，它们分别负责启动Hive服务端和与MySQL通信维护元数据。使用符号“&”使服务在后台运行。之后使用命令`jps`，发现`RunJar`进程代表启动成功。

```shell
hive --service metastore &
hive --service hiveserver2 &
```

**（6） 写下我们的第一条HQL语句**

&emsp;&emsp;使用命令`sudo ss -tulnp | grep 10000`查看连接端口所绑定地址，之后使用命令`beeline -u jdbc:hive2://address:10000 -n root`连接，注意`address`要和绑定地址对应。结果如下所示代表连接成功。

```shell
root@m1:~# sudo ss -tulnp | grep 10000
tcp   LISTEN 0      50     [::ffff:192.168.0.2]:10000            *:*    users:(("java",pid=4742,fd=689))                       
root@m1:~# beeline -u jdbc:hive2://192.168.0.2:10000 -n root
Connecting to jdbc:hive2://192.168.0.2:10000
Connected to: Apache Hive (version 4.0.0)
Driver: Hive JDBC (version 2.3.9)
Transaction isolation: TRANSACTION_REPEATABLE_READ
Beeline version 2.3.9 by Apache Hive
0: jdbc:hive2://192.168.0.2:10000> 
```

&emsp;&emsp;之后，你可以使用通常的SQL语句来操作Hive数据仓库。需要注意并不是所有的SQL语句都会被翻译成MapReduce作业来执行。我们执行我们的第一条SQL语句`show databases;`来查看所有数据库，默认只有`default`，这和常见的SQL数据库是一样的。使用`use default;`进入该数据库。

```
0: jdbc:hive2://192.168.0.2:10000> show databases;
INFO  : Compiling command(queryId=root_20250529133014_58f8cad1-376a-478a-a79b-442269320ecf): show databases
......
......
+----------------+
| database_name  |
+----------------+
| default        |
+----------------+
1 row selected (2.018 seconds)
```

&emsp;&emsp;至此，我们的Hive安装就结束了。接下来我们会介绍一下Hive的基本操作，其和SQL数据库类似。


### 5.2.2 Hive的基本操作

**（1） 创建表**

&emsp;&emsp;我们使用：

&emsp;&emsp;`create table students(id int, name string, sex string); `

来创建一个学生表，表名为`students`，表中有三个属性（三列），分别为整型的`id`、字符串的`sex`和`name`。在Hive中，不支持SQL数据库般的主键约束。在创建成功后，会在HDFS集群中的`/user/hive/warehouse/`下看到我们所创建的表：

```
root@m1:~# hdfs dfs -ls /user/hive/warehouse/
Found 1 items
drwxr-xr-x   - root supergroup          0 2025-05-29 14:02 /user/hive/warehouse/student
```

可以使用命令`desc tablename`来查看某表的表结构。可以使用`drop table tableName;`来删除表。

```
0: jdbc:hive2://192.168.0.2:10000> desc student;
INFO  : Compiling command
......
+-----------+------------+----------+
| col_name  | data_type  | comment  |
+-----------+------------+----------+
| id        | int        |          |
| name      | string     |          |
| sex       | string     |          |
+-----------+------------+----------+
3 rows selected (0.365 seconds)
```

**（2） 插入数据**

&emsp;&emsp;在这之后，我们使用：

&emsp;&emsp;`insert into student values(1,"张三", "男");`

往刚刚创建的表中插入一行数据，该学生ID为1，是名叫张三的男孩。`insert`操作翻译成MapReduce作业来执行。输入指令后，我们可以在命令行的输出中看到该操作被翻译后包括一个`mapper`和一个`reducer`，接着是MapReduce作业开始执行，每个阶段的执行情况都会给出，在最后作业完成后会给出总共耗费的CPU时间和总时间。从中我们可以看到一条简单的插入语句被翻译成MapReduce作业并执行需要耗费几乎30秒的时间！（在MySQL数据库中该花费用时远小于1秒）在执行命令时，Hive也会提醒我们翻译为MapReduce作业在未来会被逐渐弃用，建议我们改用其他引擎，这也是为什么在一开始我们说Hive的性能并不优秀。

>`WARN  : Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. tez) or using Hive 1.X releases.`

```
0: jdbc:hive2://192.168.0.2:10000> insert into student values(1,"张三", "男");
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2025-05-29 14:10:20,504 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 2.92 sec
INFO  : 2025-05-29 14:10:20,504 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 2.92 sec
2025-05-29 14:10:26,647 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 5.98 sec
MapReduce Jobs Launched: 
INFO  : Total MapReduce CPU Time Spent: 5 seconds 980 msec
INFO  : Completed executing command
No rows affected (28.38 seconds)
```

&emsp;&emsp;MapReduce作业是被调度到Yarn集群上执行的，我们可以打开Yarn集群中ResourceManager的WebUI，查看此作业的执行情况如图5-3所示。在本书的配置中，ResourceManager的WebUI位于`m3:8088`。如果你启动了JobHistory（还记得他吗？），也可以在其WebUI上看见该作业的执行历史，可以看见改作业由一个Map任务和一个Reduce任务组成。rc="/pic/5/5-3 插入作业的执行情况(1).png" width="50%">
    <br/>
    <em>图5-3 插入作业的执行情况(1)</em>
</p>如图5-4所示。本书的配置中，JobHistory的WebUI位于`m2:19888`。在JobHistory上，其会记录精确到每一个任务的执行情况，如图5-5所示。

<p align="center">
    <img s

<p align="center">
    <img src="/pic/5/5-4 插入作业的执行情况(2).png" width="50%">
    <br/>
    <em>图5-4 插入作业的执行情况(2)</em>
</p>

<p align="center">
    <img src="/pic/5/5-5 插入作业中Reduce任务的执行情况.png" width="50%">
    <br/>
    <em>图5-5 插入作业中Reduce任务的执行情况</em>
</p>

**（3） 导入数据**

&emsp;&emsp;Hive支持导入数据，其可以将结构化的数据导入为表。要这么做，首先需要根据待导入数据的格式传建表，假设在HDFS下的`hive_test/`下有一结构化的文本文件`students.txt`，我们想要将其导入为students表，其文本内容为：

```
1,小明,男
2,小红,女
3,小李,男
4,小何,女
```

&emsp;&emsp;根据该内容，我们可以创建对应的表结构：

```sql
create table students(
  id    int,
  name  string,
  sex   string
)
row format delimited
fields terminated by ','
lines terminated by '\n'
stored as textfile;
```

&emsp;&emsp;在这里我们规定了数据的行和行间使用换行符`\n`来划分，在在同一行的不同列即不同属性使用逗号`,`来划分，并且要求Hive将数据库以文本`textfile`的形式存储。接下来，我们在本地目录中创建一个如上的文本文件，并将其上传到HDFS集群中的`hive_test/`目录下

```
root@m1:~# vi students.txt
root@m1:~# hdfs dfs -mkdir /hive_test/
root@m1:~# hdfs dfs -put students.txt /hive_test/
```

&emsp;&emsp;接着，我们使用命令`load data inpath "/hive_test/students.txt" into table students;`（在这里，你可以在`inpath`前加上`local`来导入本地linux系统中的数据）将其导入到表中，并使用`select`语句来验证是否导入成功。

```
0: jdbc:hive2://192.168.0.2:10000> load data inpath "/hive_test/students.txt" into table students;
Loading data to table default.students
......
0: jdbc:hive2://192.168.0.2:10000> select * from students;
+--------------+----------------+---------------+
| students.id  | students.name  | students.sex  |
+--------------+----------------+---------------+
| 1            | 小明             | 男           |
| 2            | 小红             | 女           |
| 3            | 小李             | 男           |
| 4            | 小何             | 女           |
+--------------+----------------+---------------+
4 rows selected (0.261 seconds)
```

&emsp;&emsp;在该表的HDFS存储目录下，存储着表的数据并且以`txt`的形式保存，如图5-6，其形式和我们导入时的文本结构是一致的。

<p align="center">
    <img src="/pic/5/5-6 导入数据并以文本形式存储.png" width="50%">
    <br/>
    <em>图5-6 导入数据并以文本形式存储</em>
</p>

&emsp;&emsp;接着，我们可以看一下原来导入的`txt`文件是否还存在：

`root@m1:~# hdfs dfs -ls /hive_test`

我们可以发现，其已不存在，也就是说，在导入到Hive数据库时，Hive是直接将原始数据移动到自己的表存储目录下了，为什么是移动而不是复制呢？因为在HDFS集群中，一个文件默认存储三份，如果复制则较为占用存储空间。事实上，你可以直接将文件文件手动的放入表的存储目录下而不是使用`load`语句，表数据也能正常读出。

**（4） 导出数据**

&emsp;&emsp;你也可以将Hive中的表数据导出为指定格式的结构化的文件，例如：

```sql
insert overwrite local directory '/root/hive_out' 
row format delimited 
fields terminated by '-'
select * from students;
```

&emsp;&emsp;`select *`代表导出所有行和列，`local directory`代表导出到本地linux，`/root/hive_out`代表导出的目录。在这里我们属性间使用`-`分割，查看导出的该文件，`vi hive_out/000000_0 `，内容如下：

```
1-小明-男
2-小红-女
3-小李-男
4-小何-女
```


**（5） 查询数据**

&emsp;&emsp;你可以使用`select`语句来查询数据，`select name,id from students;`，指定只查找`name`和`id`列。

```
0: jdbc:hive2://192.168.0.2:10000> select name,id from students;
......
+-------+-------+
| name  |  id   |
+-------+-------+
| 小明    | 1    |
| 小红    | 2    |
| 小李    | 3    |
| 小何    | 4    |
+-------+-------+
4 rows selected (0.316 seconds)
```

### 5.2.3 总结

&emsp;&emsp;在该小节中我们学习了Hive的安装和一些基本的增删改查操作，我们发现，并不是所有的SQL语句都会被翻译为MapReduce作业执行，同时MapReduce作业执行SQL语句的性能并不理想，我们应该避免在Hive中使用`INSERT`语句。在下一小节中，我们会学习到Hive的一些进阶操作。