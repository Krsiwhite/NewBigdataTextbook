## 大数据核心组件：我们将会用到什么
​	看到此处，我们应该已经了解了什么是大数据、大数据处理的简单流程和优秀的大数据平台例子。也就是用什么食材，以及怎么处理食材以及成品如何。那么接下来，将探究在烹饪过程中，会用到哪些刀具。

### 1.4.1 大数据采集

​	让我们回到图1-3，大数据处理的起始应该是从数据来源收集数据，在这部分中，可以使用非常丰富的工具，例如使用不同的编程语言通过爬虫技术从互联网上爬取到信息。但严格来说，爬虫并不属于大数据技术的内容，因为其只是一种手段，可以将其用在任何场景中，并不和大数据处理强绑定。

​	在采集环节，常用到的两个组件分别是Flume和Kafla，二者更详细的介绍将会在后面的章节中提到，总的来说，他们的作用都是从不同来源收集不同结构的数据，再统一地发送给不同的消费者，例如发送给储存组件做持久化，或是发送给运算组件做计算。见图1-7。
<p align="center">
    <img src="/pic/1/1-7 Kafla、Flume.png" width="50%">
    <br/>
    <em>图1-7 Kafla、Flume</em>
</p>

### 1.4.2 大数据存储

​	数据采集完成后，接下来需要解决的是数据的存储问题。与传统的数据存储不同，大数据存储面临更多的挑战。简单来说，海量的数据无法存储在一台设备上，需要多台设备协同服务，那么如何决定即将到来的数据将存储在哪？当某台设备出现故障该如何解决？如何快速响应用户的读写请求？如何扩展我们的存储阵列？

​	在大数据生态中，HDFS能解决这些问题，这是一个分布式文件系统。其核心设计思想是将超大文件分割成块，并拷贝多次分布式地存储在集群的多个节点上。如图1-8。


<p align="center">
    <img src="/pic/1/1-8 HDFS将数据分散到多个节点.png" width="50%">
    <br/>
    <em>图1-8 HDFS将数据分散到多个节点</em>
</p>

​	在此之上，许多的场景中，你可能需要低延时的随机访问，或者你想维护表组织的数据，那么就会需要HBase，这是一个分布式的，可扩展，面向列簇的数据库，底层依赖HDFS进行存储，支持行级/列级随机访问（访问一列，一行）。可以简单理解为HDFS就像自家电脑上的文件系统，可以用其随意存储数据，可以在不同的文件夹里放入不同的文件，这些文件被切成一个一个的块存在多个设备中，而HBase可以构建一个表形的数据，所有的结构打包在一个文件里，如上一般存储在HDFS中。如图1-9。


<p align="center">
    <img src="/pic/1/1-9 HBase和HDFS关系.webp" width="50%">
    <br/>
    <em>图1-9 HBase和HDFS关系</em>
</p>

### 1.4.3 大数据处理

​	存储之后的数据需要经过计算处理才能产生价值，大数据计算框架根据处理模式可大致分为两类：

​	一类叫做批处理运算，什么叫批处理？当作为一名厨师，准备好了各种食材之后，顾客们便会开始点菜，批处理的运作方式是，它会等待顾客点到足够多的菜，再一次性地跑去后厨把菜全做出来。这一个简单的例子帮助我们了解了批处理运算的诸多特性：定时处理（攒够一定数据量/时间才启动计算），全量计算（每次处理所有数据），延迟较高（从数据开始产生到出结果需要较长时间）。常见的批处理计算框架有MapReduce、Spark。

​	另一类叫做流处理运算，和批处理相对，流处理运算中，顾客每点一道菜后厨都会立即响应，做菜，这会使得上菜速度显著加快，但同时也会需要厨房不间断待命。数据像水流一样源源不断，来一条处理一条，其最大的特点是低延迟和实时处理，在必须实时响应的场景作用非凡，其和批处理运算相比优势也在于此，但同时，流处理的花销会更大。常见的流处理计算框架有Storm、Flink等。


<p align="center">
    <img src="/pic/1/1-10 批处理和流处理.png" width="50%">
    <br/>
    <em>图1-10 批处理和流处理</em>
</p>

### 1.4.4 大数据分析

​	在传统的数据库中，我们使用SQL语言编写事务来帮助我们查询、分析需要的数据，SQL语言的入门和学习相对比较简单，这导致在传统的数据分析领域产生了“SQL Boy”这一自嘲式称呼，通常指那些过度依赖 SQL 技能而缺乏更广泛技术能力的数据从业者。从这可以看出SQL语言在传统数据库领域的广泛、易用。

​	倘若在大数据分析中，也能使用SQL语句，岂不是可以帮助工程师们更好的从传统数据分析中迁移过来？答案是当然的，所以Hive诞生了，其可以利用简单的SQL语句(简称HQL)来查询、分析存储在HDFS中的数据，并把SQL语句转换成相适配的程序来进行处理，这降低了大数据分析的学习成本。常见的类似组件还有Drill、Kylin等。

