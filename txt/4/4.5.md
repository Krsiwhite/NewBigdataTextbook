## 4.5 其他常见流处理框架

&emsp;&emsp;在4.4节中，我们接触到了Storm，但除了Storm外，业界还存在许多优秀的开源或商业流处理框架。本节中，我们将简要介绍几种常见的流处理框架。

### 4.5.1 Spark Streaming

&emsp;&emsp;在大数据时代，许多业务场景都对实时数据处理提出了要求，例如金融风控、实时推荐、舆情监测等。Spark Streaming 正是应对这种需求而生的一个基于 Spark 批处理框架的流处理引擎。与传统的“纯流式处理”不同，Spark Streaming 并非一条条逐条处理数据，而是采用了一种称为“微批处理（Micro-Batch）”的模型。可以想象有一条源源不断的实时数据流，我们不会逐条处理，而是每隔几秒（如1秒或2秒）把这段时间内的数据“打包”成一个小批次（mini-batch），然后像处理批数据那样进行统一调度和并行计算。

**（1）Spark Streaming整体架构与数据流动路径**

&emsp;&emsp;Spark Streaming 可以接入来自多种来源的数据，包括 Kafka、Flume、Socket、Twitter、HDFS、Amazon Kinesis 等。在图4-5中我们数据源输入到Spark Streaming中。
<p align="center">
    <img src="/pic/4/4-5 Spark Streaming处理流程.png" width="50%">
    <br/>
    <em>图4-5 Spark Streaming处理流程</em>
</p>

&emsp;&emsp;Spark Streaming 是整个系统的核心，负责：
   - 持续地接收来自输入源的数据流；
   - 将数据划分成时间窗口（micro-batches）；
   - 使用 Spark 的强大计算能力进行实时分析处理，比如过滤、聚合、转化等；
   - 将处理后的数据发送给下游系统。

&emsp;&emsp;处理完的数据可以被写入以下目标：
   - HDFS：用于持久化存储。
   - Databases：如 MySQL、PostgreSQL、Cassandra 等，便于后续查询分析。
   - Dashboards：实时可视化系统，例如 Apache Superset、Grafana 等，用于业务监控和报警。

**（2）Spark Streaming中离散化流（DStream）**

 &emsp;&emsp;通过将连续的数据流分解为一系列时间间隔内的RDD（弹性分布式数据集），每个RDD代表一个特定时间段内的数据集合，从而实现了对实时数据的批处理。具体而言，随着时间推移，数据被分割成固定大小的时间窗口，每个窗口对应一个RDD，如图4-6所示，time 1至time 4分别生成各自的RDD。

 &emsp;&emsp;在处理阶段，Spark Streaming 提供了丰富的 API 来对这些小批次（其实就是 RDD）执行转换操作，比如 map、filter、reduce、join 等，还支持窗口操作（window）、状态维护（updateStateByKey）等高级功能。
   - 窗口操作（window）允许我们对多个连续的微批（micro-batches）进行合并计算，从而实现基于时间窗口的聚合分析（如滑动平均、滚动求和、统计计数等）。
   - updateStateByKey 允许我们在保证容错性的前提下，将每个 key 对应的上一次状态与本次到来的新数据结合，更新并保存新的状态。

 &emsp;&emsp;最终，处理结果可以被输出到 HDFS、数据库、控制台，或者发送到外部消息队列中（如 Kafka 或其他系统），实现端到端的实时数据处理。

<p align="center">
    <img src="/pic/4/4-6 Dstream与RDD.png" width="50%">
    <br/>
    <em>图4-6 Dstream与RDD</em>
</p>

&emsp;&emsp;以上就是 Spark Streaming 的标准处理流程，其整体结构可类比为数据流的四道工序：采集、分批、处理、输出。

&emsp;&emsp;在 Spark Streaming 中，最核心的概念是 DStream（Discretized Stream，离散流）。DStream 代表的是一个逻辑上的连续数据流，但它的底层结构其实是由一系列 时间序列上的 RDD 构成。每个时间窗口内产生一个 RDD，多个时间点上连续生成的 RDD 组成了这个 DStream。

&emsp;&emsp;你可以将 DStream 类比为一条“实时传送带”，每隔一段时间生成一个小批次数据单元（一个 RDD）。每个小批次就像一个“数据箱子”，通过连续处理这些 RDD，即可实现整个数据流的处理任务。


### 4.5.2 Flink

**（1）批与流**

   - 批处理的特点是有界、持久、大量，非常适合需要访问全套记录才能完成的计算工作，一般用于离线统计。 
   - 流处理的特点是无界、实时, 无需针对整个数据集执行操作，而是对通过系统传输的每个数据项执行操作，一般用于实时统计。
   
&emsp;&emsp;如图4-7所示，在Spark的世界观中，一切都是由批次组成的，离线数据是一个大批次，而实时数据是由一个一个无限的小批次组成的。而在Flink的世界观中，一切都是由流组成的，离线数据是有界限的流，实时数据是一个没有界限的流，这就是所谓的有界流和无界流。

<p align="center">
    <img src="/pic/4/4-7 Flink批次.png" width="50%">
    <br/>
    <em>图4-7 Flink批次.png</em>
</p>

   - 无界流：有定义流的开始，但没有定义流的结束。它们会无休止地产生数据。无界流的数据必须持续处理，即数据被摄取后需要立刻处理。我们不能等到所有数据都到达再处理，因为输入是无限的，在任何时候输入都不会完成。处理无界数据通常要求以特定顺序摄取事件，例如事件发生的顺序，以便能够推断结果的完整性。
   - 有界流：有定义流的开始，也有定义流的结束。有界流可以在摄取所有数据后再进行计算。有界流所有数据可以被排序，所以并不需要有序摄取。有界流处理通常被称为批处理。


**（2）Flink的部署应用**

&emsp;&emsp;Apache Flink 是一个分布式系统，它需要计算资源来执行应用程序。Flink 集成了所有常见的集群资源管理器，例如Hadoop YARN、 Apache Mesos和 Kubernetes，但同时也可以作为独立集群运行。

&emsp;&emsp;Flink 被设计为能够很好地工作在上述每个资源管理器中，这是通过资源管理器特定(resource-manager-specific)的部署模式实现的。Flink 可以采用与当前资源管理器相适应的方式进行交互。
   
&emsp;&emsp;部署 Flink 应用程序时，Flink 会根据应用程序配置的并行性自动标识所需的资源，并从资源管理器请求这些资源。在发生故障的情况下，Flink 通过请求新资源来替换发生故障的容器。提交或控制应用程序的所有通信都是通过 REST 调用进行的，这可以简化 Flink 与各种环境中的集成。

&emsp;&emsp;如图4-8所示，有状态的 Flink 程序针对本地状态访问进行了优化。任务的状态始终保留在内存中，如果状态大小超过可用内存，则会保存在能高效访问的磁盘数据结构中。任务通过访问本地（通常在内存中）状态来进行所有的计算，从而产生非常低的处理延迟。Flink 通过定期和异步地对本地状态进行持久化存储来保证故障场景下精确一次的状态一致性。

<p align="center">
    <img src="/pic/4/4-8 Flink内存利用.png" width="50%">
    <br/>
    <em>图4-8 Flink内存利用</em>
</p>

&emsp;&emsp;Spark Streaming 是整个系统的核心，负责：
   - 持续地接收来自输入源的数据流；
   - 将数据划分成时间窗口（micro-batches）；
   - 使用 Spark 的强大计算能力进行实时分析处理，比如过滤、聚合、转化等；
   - 将处理后的数据发送给下游系统。

&emsp;&emsp;处理完的数据可以被写入以下目标：
   - HDFS：用于持久化存储。
   - Databases：如 MySQL、PostgreSQL、Cassandra 等，便于后续查询分析。
   - Dashboards：实时可视化系统，例如 Apache Superset、Grafana 等，用于业务监控和报警。

**（2）Flink分层API**

&emsp;&emsp;Apache Flink 是一个框架和分布式处理引擎，用于在无边界和有边界数据流上进行有状态的计算。Flink 能在所有常见集群环境中运行，并能以内存速度和任意规模进行计算。

&emsp;&emsp;Apache Flink 功能强大，支持开发和运行多种不同种类的应用程序。它的主要特性包括：批流一体化、精密的状态管理、事件时间支持以及精确一次的状态一致性保障等。Flink 不仅可以运行在包括 YARN、 Mesos、Kubernetes 在内的多种资源管理框架上，还支持在裸机集群上独立部署。在启用高可用选项的情况下，它不存在单点失效问题。事实证明，Flink 已经可以扩展到数千核心，其状态可以达到 TB 级别，且仍能保持高吞吐、低延迟的特性。世界各地有很多要求严苛的流处理应用都运行在 Flink 之上。

&emsp;&emsp;接下来，我们来介绍一下Flink中的几个重要概念

 &emsp;&emsp;Flink 根据抽象程度分层，提供了三种不同的 API。每一种 API 在简洁性和表达力上有着不同的侧重，并且针对不同的应用场景。

<p align="center">
    <img src="/pic/4/4-9 Flink分层API.png" width="50%">
    <br/>
    <em>图4-9 Flink分层API</em>
</p>

   - ProcessFunction：可以处理一或两条输入数据流中的单个事件或者归入一个特定窗口内的多个事件。它提供了对于时间和状态的细粒度控制。开发者可以在其中任意地修改状态，也能够注册定时器用以在未来的某一时刻触发回调函数。因此，你可以利用ProcessFunction实现许多有状态的事件驱动应用所需要的基于单个事件的复杂业务逻辑。
   - DataStream API：为许多通用的流处理操作提供了处理原语。这些操作包括窗口、逐条记录的转换操作，在处理事件时进行外部数据库查询等。DataStream API 支持 Java 和 Scala 语言，预先定义了例如map()、reduce()、aggregate() 等函数。你可以通过扩展实现预定义接口或使用 Java、Scala 的 lambda 表达式实现自定义的函数。
   - SQL & Table API：Flink 支持两种关系型的 API，Table API 和 SQL。这两个 API 都是批处理和流处理统一的 API，这意味着在无边界的实时数据流和有边界的历史记录数据流上，关系型 API 会以相同的语义执行查询，并产生相同的结果。Table API和SQL借助了 Apache Calcite来进行查询的解析，校验以及优化。它们可以与DataStream和DataSet API无缝集成，并支持用户自定义的标量函数，聚合函数以及表值函数。Flink 的关系型 API 旨在简化数据分析、数据流水线和 ETL 应用的定义。