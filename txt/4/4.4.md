## 4.4 

### 4.4.1 Storm

#### 4.4.1.1 Storm的工作原理

&emsp;&emsp;Storm是一个分布式、可靠、容错的实时流式数据处理的系统。在Storm中，先要设计一个用于实时计算的图状结构，我们称之为拓扑（topology）。这个拓扑将会被提交给集群，由集群中的主控节点（master node）分发代码，将任务分配给工作节点（worker node）执行。一个拓扑中包括spout和bolt两种角色，其中spout发送消息，负责将数据流以tuple元组的形式发送出去；而bolt则负责转换这些数据流，在bolt中可以完成计算、过滤等操作，bolt自身也可以随机将数据发送给其他bolt。由spout发射出的tuple是不可变数组，对应着固定的键值对。

#### 4.4.1.2 Storm的安装配置

**环境准备**：

- Java 8
- Zookeeper 3.8.4

**安装步骤**：

1. **下载Storm**：

```bash
# 下载Storm 2.5.0版本（由于清华镜像中没有2.5.0版本的Storm，所以使用中央仓库的。国外镜像访问速度可能较慢）
wget https://archive.apache.org/dist/storm/apache-storm-2.5.0/apache-storm-2.5.0.tar.gz

# 解压
tar -zxvf apache-storm-2.5.0.tar.gz
```

2. **环境变量配置**：

```bash
# 在m1上，编辑/etc/profile
export STORM_HOME=/root/apache-storm-2.5.0
export PATH=$PATH:$STORM_HOME/bin

# 拷贝环境变量到m2，m3中：
scp -r /etc/profile m2:/etc
scp -r /etc/profile m3:/etc


# 在三台机器上分别执行如下代码，使环境变量生效
source /etc/profile
```

3. **配置storm**：

```bash
# 进入storm配置目录，配置storm.yaml
cd ${STORM_HOME}/conf
编辑storm.yaml，添加如下内容：
storm.zookeeper.servers: # 这里输入三台服务器的名称
     - "m1"
     - "m2"
     - "m3"
# nimbus nodes list
nimbus.seeds: ["m1"]
# nimbus host node
nimbus.host: "m1"
# Web页面端口号
ui.port: 8081
# workers进程的端口，每一个worker进程都会使用一个端口来接收消息
supervisor.slots.ports:
  - 6700
  - 6701
  - 6702
  - 6703
storm.local.dir: "/root/storm/data"

# 创建storm数据文件目录
mkdir /root/storm/data
# 注：supervisor.slots.ports 参数用来配置 workers 进程接收消息的端口，默认每个 supervisor 节点上会启动 4 个 worker，当然你也可以按照自己的需要和服务器性能进行设置，假设只想启动 2 个 worker 的话，此处配置 2 个端口即可。

# 拷贝配置文件到m2，m3中：
scp -r /root/apache-storm-2.5.0 m2:/etc
scp -r /root/apache-storm-2.5.0 m3:/etc
```

4. **启动storm**：

```bash
# 启动Storm之前，首先启动zookeeper集群。
# 在三台服务器上，分别执行：
zkServer.sh start

# 在m1上开启nimbus进程：
storm nimbus &

#正常没问题的情况应该会显示“[1] 进程号”然后没有其他消息。
#但首次启动有可能出现如下报错：
#Need python version > 2.6
#这是因为storm启动依赖特定的组件，而这些组件需要python 2.6以上的版本。
#如果你是一直按照本书进行实验的，那你的服务器上应该已经安装了python3的，只是storm默认识别到了其他版本的python，我们可以通过软链接的方式避开这个问题，在三台机器上执行下面这条命令实现软链接：
update-alternatives --install /usr/bin/python python /usr/bin/python3 1

#保存文件后，拷贝storm文件到另外两台机器上
scp -r /root/apache-storm-2.5.0 m2:/root
scp -r /root/apache-storm-2.5.0 m3:/root

#然后再在m1上输入 
storm nimbus &

#新开一个m1窗口检查jps，nimbus显示已成功启动。
#在m2，m3上开启supervisor进程
storm supervisor &

#此时m2和m3的jps出现supervisor，即表示启动成功。

#如果需要在web上查看storm部署情况，可以新开m1控制台或Ctrl+C之后，继续执行如下指令
storm ui & （这个时候jps会多一个core）
storm logviewer & （这个时候jps会多一个logviewer）
#之后访问https://1.92.64.216:8081/。（注意：1.92.64.216指的是m1主机，即nimbus主机的公网地址。输入私网地址打不开！读者配置时根据自己实际的公网地址替换）。
#到此，storm的安装配置过程完成。
```

#### 4.4.1.3 Flume+Kafka+Storm+HBase结合实战

&emsp;&emsp;接下来我们将Kafka消费者收到的消息通过Storm处理转换为全小写并放入HBase储存，这将帮助我们体会到流处理更完整的流程

**环境准备**：

- Java 8
- Hadoop 3.3.6
- HBase 2.5.11
- ZooKeeper 3.8.4
- Flume 1.11.0
- Kafka 3.9.1
- Storm 2.5.0
- 3台服务器（m1、m2、m3）

**数据流**：

&emsp;&emsp;Flume输入数据 -> Kafka消费者接收数据 -> Storm消费Kafka消费者接收的数据并处理 -> HBase存储Storm处理后的数据。

1. **准备工作**：

```bash
# 启动Zookeeper
# 由于Kafka依赖于Zookeeper管理集群信息。因此在启动Kafka之前，需要先启动zookeeper。
# 在m1，m2，m3三台机器分别执行
zkServer.sh start

# 启动Hadoop&HBase
# 在m1上启动Hadoop
start-dfs.sh

# 在m3上启动HBase：
start-hbase.sh

# 启动Kafka
# 在m1，m2，m3三台机器分别执行（-daemon是守护进程，后台执行）：
cd ${KAFKA_HOME}
bin/kafka-server-start.sh -daemon config/server.properties

# 启动Storm
#在m1上输入
storm nimbus &

#在m2，m3上开启supervisor进程
storm supervisor &

# 创建HBase表格
#在m3上，输入
hbase shell

#创建表格
create ‘storm_test’, ‘cf’

# 启动Flume Agent
flume-ng agent --conf conf --conf-file ${FLUME_HOME}/conf/flume.conf --name agent1 -Dflume.root.logger=INFO,console
```

&emsp;&emsp;此时三台服务器上输入jps，分别为：
```bash
# m1
DFSZKFailoverController
Kafka
HRegionServer
NameNode
Application
Nimbus
Jps
JournalNode
QuorumPeerMain

# m2
DFSZKFailoverController
Kafka
HRegionServer
NameNode
ConsoleConsumer
Supervisor
Jps
JournalNode
QuorumPeerMain

# m3
DFSZKFailoverController
Kafka
HMaster
HRegionServer
DataNode
ConsoleConsumer
Supervisor
Jps
JournalNode
QuorumPeerMain
```

2. **搭建程序**:

&emsp;&emsp;该程序旨在于演示Storm处理Kafka消费者数据的功能，以转化为小写进行演示。并将输入的数据存储到HBase。
使用IntelliJ IDEA创建Maven项目，名称：FlumeKafkaStormHBase，JDK：JDK 1.8，GroupId：bigdatatextbook，ArtifactId: FlumeKafkaStormHBase

&emsp;&emsp;java代码如下：

&emsp;&emsp;主程序：KafkaSpoutHBaseTopology.java

```java
package bigdatatextbook;
import org.apache.storm.Config;
import org.apache.storm.LocalCluster;
import org.apache.storm.StormSubmitter;
import org.apache.storm.generated.StormTopology;
import org.apache.storm.kafka.spout.KafkaSpout;
import org.apache.storm.kafka.spout.KafkaSpoutConfig;
import org.apache.storm.task.OutputCollector;
import org.apache.storm.task.TopologyContext;
import org.apache.storm.topology.OutputFieldsDeclarer;
import org.apache.storm.topology.TopologyBuilder;
import org.apache.storm.topology.base.BaseRichBolt;
import org.apache.storm.tuple.Tuple;

import java.util.Map;
import org.apache.hadoop.hbase.HBaseConfiguration;
import org.apache.hadoop.hbase.client.Connection;
import org.apache.hadoop.hbase.client.ConnectionFactory;
import org.apache.hadoop.hbase.client.Put;
import org.apache.hadoop.hbase.client.Table;
import org.apache.hadoop.hbase.util.Bytes;

public class KafkaStormHBaseTopology {


    public static class HBaseStorageBolt extends BaseRichBolt {
        private Connection connection;
        private Table table;

        @Override
        public void prepare(Map<String, Object> map, TopologyContext topologyContext, OutputCollector outputCollector) {
            try {
                connection = ConnectionFactory.createConnection(HBaseConfiguration.create());
                table = connection.getTable(org.apache.hadoop.hbase.TableName.valueOf("storm_test"));
            } catch (Exception e) {
                throw new RuntimeException("无法连接到HBase", e);
            }
        }

        @Override
        public void execute(Tuple tuple) {
            try {
                // 获取原始值并转为小写
                String value = tuple.getStringByField("value").toLowerCase();
                // 使用"row_时间戳"作为row key避免重复
                String rowKey = "row_" + System.currentTimeMillis();
                Put put = new Put(Bytes.toBytes(rowKey));
                put.addColumn(Bytes.toBytes("cf"), Bytes.toBytes("qualifier"), Bytes.toBytes(value));
                table.put(put);
            } catch (Exception e) {
                throw new RuntimeException("无法将数据存入Hbase", e);
            }
        }


        @Override
        public void declareOutputFields(OutputFieldsDeclarer declarer) {
            // No output fields to declare for HBase storage
        }

        @Override
        public void cleanup() {
            try {
                if (table != null) table.close();
                if (connection != null) connection.close();
            } catch (Exception e) {
                throw new RuntimeException("无法关闭Hbase资源", e);
            }
        }
    }

    public static StormTopology buildTopology(String bootstrapServers, String topic) {
        KafkaSpoutConfig<String, String> kafkaSpoutConfig = KafkaSpoutConfig.builder(bootstrapServers, topic)
                .setProp("group.id", "storm-kafka-group")  // 添加 group.id 属性
                .build();

        TopologyBuilder builder = new TopologyBuilder();
        builder.setSpout("kafka-spout", new KafkaSpout<>(kafkaSpoutConfig));
        builder.setBolt("hbase-storage-bolt", new HBaseStorageBolt()).shuffleGrouping("kafka-spout");

        return builder.createTopology();
    }

    public static void main(String[] args) throws Exception {
        String bootstrapServers = "m1:9092,m2:9092,m3:9092";
        String topic = "mylog";

        StormTopology topology = buildTopology(bootstrapServers, topic);

        Config config = new Config();
        config.setDebug(true);

        StormSubmitter.submitTopology(
                "storm_topology",
                config,
                topology
        );
        System.out.println("拓扑提交成功");
    }
}
```

&emsp;&emsp;此外，需要编辑pom.xml：

```bash
<?xml version="1.0" encoding="UTF-8"?>
<project xmlns="http://maven.apache.org/POM/4.0.0"
         xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
         xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd">
    <modelVersion>4.0.0</modelVersion>

    <groupId>bigdatatextbook</groupId>
    <artifactId>FlumeKafkaStormHBase</artifactId>
    <version>1.0</version>

    <properties>
        <maven.compiler.source>8</maven.compiler.source>
        <maven.compiler.target>8</maven.compiler.target>
        <project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>
    </properties>
    <dependencies>
        <dependency>
            <groupId>org.apache.storm</groupId>
            <artifactId>storm-core</artifactId>
            <version>2.5.0</version>
        </dependency>
        <dependency>
            <groupId>org.apache.kafka</groupId>
            <artifactId>kafka-clients</artifactId>
            <version>3.9.1</version>
        </dependency>
        <dependency>
            <groupId>org.apache.storm</groupId>
            <artifactId>storm-kafka-client</artifactId>
            <version>2.5.0</version>
        </dependency>
        <!-- HBase Client -->
        <dependency>
            <groupId>org.apache.hbase</groupId>
            <artifactId>hbase-client</artifactId>
            <version>2.5.11</version>
        </dependency>
    </dependencies>
    <build>
        <plugins>
            <!-- 打包插件 -->
            <plugin>
                <groupId>org.apache.maven.plugins</groupId>
                <artifactId>maven-shade-plugin</artifactId>
                <version>3.2.4</version>
                <executions>
                    <execution>
                        <phase>package</phase>
                        <goals>
                            <goal>shade</goal>
                        </goals>
                        <configuration>
                            <transformers>
                                <!-- 指定主类 -->
                                <transformer implementation="org.apache.maven.plugins.shade.resource.ManifestResourceTransformer">
                                    <manifestEntries>
                                        <Main-Class>bigdatatextbook.KafkaStormHBaseTopology</Main-Class>
                                    </manifestEntries>
                                </transformer>
                            </transformers>
                            <!-- 排除签名文件 -->
                            <filters>
                                <filter>
                                    <artifact>*:*</artifact>
                                    <excludes>
                                        <exclude>META-INF/*.SF</exclude>
                                        <exclude>META-INF/*.DSA</exclude>
                                        <exclude>META-INF/*.RSA</exclude>
                                        <exclude>defaults.yaml</exclude>
                                        <exclude>storm.yaml</exclude>
                                    </excludes>
                                </filter>
                            </filters>
                        </configuration>
                    </execution>
                </executions>
            </plugin>
        </plugins>
    </build>
</project>
```

&emsp;&emsp;完成编程后，加载maven项目，在maven项目处首先使用clean然后package打包为jar，对项目目录/target下的jar改名为FlumeKafkaStormHBase.jar,并将该jar包上传到m1机器的/root目录。

3. **Kafka配置**：

```bash
# 在4.3节，已经创建好了Kafka的topic，名称为mylog，在这里的实验我们继续使用该topic。
# 监听Kafka，创建消费者
#在m2上，启动kafka消费者
cd ${KAFKA_HOME}
bin/kafka-console-consumer.sh --bootstrap-server m1:9092,m2:9092,m3:9092 --topic mylog --from-beginning
```

4. **运行程序**：

```bash
# 在m1上运行jar包：
storm jar FlumeKafkaStormHBase.jar bigdatatextbook.KafkaStormHBaseTopology
```

&emsp;&emsp;运行成功之后，开始进行数据传输：

```bash
# 新开一个m1终端，使用telnet连接
telnet m1 4141
# 然后可以输入任意信息，观察Flume控制台的输出，以及Kafka消费者的输出
HELLO WORLD!
Hello World!
```

&emsp;&emsp;接着，m2控制台监听kafka的消费者会消费该消息，并在控制台上输出telnet输入的消息，此后，消息会自动通过拓扑自动转为小写，并存储至HBase中。

5. **查看已存储消息**：

```bash
#在m3机器上输入：
Hbase shell

#查看hbase表格数据
scan ‘storm_test’

#即可看到刚才消费者消费的消息数据，rowkey为row_时间戳，column cf:qualifier，然后出现刚才消费的内容（完成小写转换后的）。
```

6. **通过Storm UI观察拓扑运行情况**：

&emsp;&emsp;在m1机器上输入
`storm ui &`

&emsp;&emsp;打开http://1.92.64.216:8081/（需要替换成m1机器的公网地址）

&emsp;&emsp;打开Topology Summary下面的拓扑名称“storm_topology”，可以看到拓扑的运行情况。

&emsp;&emsp;到此，本实验结束。
