## 3.4 Spark介绍

&emsp;&emsp;Apache Spark是专为大规模数据处理而设计的快速通用的计算引擎，是加州大学伯克利分校AMP实验室开源的类 MapReduce的通用并行框架。经过多年的高速发展，Spar从目前已经成为大数据计算领域最热门的技术之一。自从Spark将仓库部署到GitHub平台之后，截至2025年5月一共有44488次提交，41.2K星，足以说明其开源社区的活跃度，其目前仍然是最受欢迎的集群运算框架之一。

<p align="center">
    <img src="/pic/3/3-8 Spark在github仓库.png" width="50%">
    <br/>
    <em>图3-8 Spark在github仓库</em>
</p>


&emsp;&emsp;时至今日，Spark已发展出了自己不同于Hadoop的独立的生态，如图3-9所示，而在目前，Spark生态所提供的所有功能远不止于此，总的来说，Spark提供了一个比MapReduce更快、更通用调度数据处理平台。

* Apache Spark Core：为Spark的核心，提供批处理框架，这也是我们本书会继续讨论的部分。
* Spark Streaming：依靠底层的批处理框架提供流处理服务。
* Spark MLlib：提供机器学习支持，目前逐渐被Spark ML取代。
* Spark GraphX：提供处理巨量图数据的能力。

<p align="center">
    <img src="/pic/3/3-9 Spark生态.png" width="50%">
    <br/>
    <em>图3-9 Spark生态</em>
</p>


### 3.4.1 提出 Spark 的原因

&emsp;&emsp;Spark是借鉴MapReduce发展而来的，它继承了MapReduce分布式并行计算的优点，改进了MapReduce明显的缺陷。MapReduce的缺陷主要体现在以下几方面：

* 在MapReduce产生的年代，内存空间较为不足，故MapReduce的计算是基于磁盘进行的，在Map阶段会将数据从磁盘读入内存中处理，而处理完成后会将输出写入磁盘中的临时文件，而在 Reduce阶段，Reduce任务会从磁盘上读取Map阶段的中间结果后再进行处理。如此大量地移动数据、与磁盘交互会大大降低处理速度，导致执行效率低，时间开销大，而目的仅仅只是为了节省内存。时至今日，内存的获取已不再昂贵，而速度才是人们所重点关注的。
* 仅支持Map、Reduce两种语义操作，表达不够丰富，为了进行分布式处理牺牲了处理的复杂性。例如在进行单机编程时，我们可以将数据提取出来做非常复杂的操作，而若使用MapReduce进行分布式处理，就必须强制地以将任务拆分成Map、Reduce两阶段的编程范式来实现，这使得编程变得死板、不灵活。
* MapReduce专注于批处理任务，而无法很好地解决许多其他大数据处理场景，这使得需要安装其他多个组件来完成，这些组件相互独立，各自运行，维护成本很高。
  
&emsp;&emsp;Spark以多种方式改进了MapReduce的缺点：

* Spark通过引进了弹性分布式数据集（Resilient Distributed Dataset, RDD），把中间数据放在内存上，只在在最初时从磁盘中加载数据，磁盘读写的次数比MapReduce少得多，迭代计算效率高。Spark的宗旨是：移动计算、不移动数据。旨在减少数据传输的开销，提高计算效率。其核心思想是将计算任务尽可能的放在数据所在的节点上执行，而不是将数据传输到计算节点。
* Spark提供了多种对RDD的操作，可分为转换（Transformation）操作和行动（Action）操作两类。转换操作包括Map、Filter、FlatMap、Sample和Sort等；行动操作包括Collect、Reduce、Lookup和Save等，简单来说，行动操作是真正会产生输出的操作（例如将数据保存到磁盘，显示在控制台上等）。所能表达的行为模式要比MapReduce更加丰富。
* 基于Spark Core的批处理框架上提供了对多种大数据处理场景的支持，例如Spark Streaming、Spark GraphX和Spark SQL等。


### 3.4.2 弹性分布式数据集（RDD）

&emsp;&emsp;RDD是Spark中对数据和计算的抽象，是Spark中最核心的概念，其特点如下：

* 其分布在集群中的只读数据集。
* 由多个Partition组成。
* 主要存储在内存中，当内存资源不足时，会自动将 RDD 数据写入磁盘。
* 只能由外部存储系统（一般为HDFS）的数据集或是另一个RDD转换而来。
* 一个RDD可以由前文所说的转换操作转换为另一个RDD。
* 弹性：由于RDD来源固定，当计算出错，数据丢失时可以通过自己的数据源重新计算。
  
&emsp;&emsp;我们还是以之前学习MapReduce时举的例子：单词计数来说明Spark如何基于RDD来完成任务，Spark完成单词技术的整体流程如图3-11所示。

<p align="center">
    <img src="/pic/3/3-11 Spark完成单词计数.png" width="50%">
    <br/>
    <em>3-11 Spark完成单词计数.png</em>
</p>

1. 首先Spark会利用`textFile`方法（这类似于MapReduce中的`TextInputFormat`）将数据从HDFS中读取，其成为RDD1。上文提到，RDD由多个Partition组成，默认情况下，如果待处理文件分布在HDFS集群的四个Block中，那此时读出的第一个RDD就会有四个Partition，每个Block对应一个Partition。类似于MapReduce，经过此步后，RDD1中文件就以一行一行的形式组织了。
2. 之后RDD1经过了一个转换操作`flatMap`，此操作将一行字符拆分成一个一个的字符串并保存在新的RDD2中（因为RDD是只读的）。
3. 之后RDD2经过了一个转换操作`Map`，将每个单词转换为为了`<Word, 1>`键值对并保存在新的RDD3中。（步骤1，2，3合并就类似于MapReduce中的Map阶段）
4. 之后RDD3经过了一个转换操作`ReduceByKey`，我们可以看到四个Partition变为了三个，这类似于MapReduce中的Shuffle，根据Key的不同将数据分到不同的Partition中，这样就产生了RDD4。
5. 之后RDD4经过了一个行动操作`saveAsTextFile`，将RDD4的数据格式化保存在HDFS集群中，至此整个任务结束。

&emsp;&emsp;从中我们可以看出Spark中数据的依赖性，在此例子中数据的流动形成了一张有向无环图（DAG），或者说，只有数据的流动没有产生环，才有最终计算的可能，大家可以思考这其中的关系。在Spark中，将数据的依赖分为两种，如图3-12所示。


<p align="center">
    <img src="/pic/3/3-12 Spark中的两种依赖.png" width="50%">
    <br/>
    <em>3-12 Spark中的两种依赖.png</em>
</p>

&emsp;&emsp;一种叫窄依赖（Narrow Dependency），父RDD中的分区最多只能被一个子RDD的一个分区使用，子RDD如果有部分分区数据丢失或损坏，只需从对应的父RDD重新计算恢复（即该节中最开始提到的RDD的弹性特点），例如：map、filter、union操作产生的都是窄依赖。

&emsp;&emsp;另一种叫宽依赖（Shuffle/Wide Dependency），子RDD分区依赖父RDD的所有分区，如果子RDD部分或全部分区数据丢失或损坏，必须从所有父RDD分区重新计算。相对于窄依赖，当分区数据损坏时，宽依赖付出的代价要高很多，故应尽量避免使用宽依赖。例如：groupByKey、reduceByKey、sortByKey操作产生的都是宽依赖。

### 3.4.3 Spark程序运行架构

&emsp;&emsp;Spark集群的工作方式和3.4.2中的Yarn类似，其也是主从架构，其有以下几个主要角色：

* Driver，类似于Yarn中的Application Master，负责调度一个作业中所有任务的执行。
* Master，类似于Yarn中的ResourceManager，负责调度整个集群的资源，为集群的主节点。
* Worker，类似于Yarn中的NodeManager，负责具体任务的执行。

<p align="center">
    <img src="/pic/3/3-13 Spark程序运行架构.png" width="50%">
    <br/>
    <em>3-13 Spark程序运行架构.png</em>
</p>

&emsp;&emsp;一个作业的启动流程大致如下，其过程与Yarn相似。

1. 客户端提交任务，创建Driver进程并初始化SparkContext。
2. Driver向Master申请资源。Master选择合适的Worker节点创建Executor，Executor类似Yarn中的Container，包含运行任务所需各种资源，不同之处在于一个Worker能运行多个Task，而一个Container只能运行一个Task。
3. Executor向Driver端注册，并等待其分配Task任务。
4. SparkContext构建DAG图（有向无环图）、分配Task至Executor。
5. Executor启动Task线程执行具体任务。


### 3.4.4 Spark的运行模式

&emsp;&emsp;Spark不同于Yarn内置于Hadoop中，是Hadoop生态的一部分；其是一个独立的整体，可以单独运行；也可通过Yarn接入Hadoop生态中。Spark的运行模式主要包括三种：
1. Local
2. Standalone
3. Yarn

&emsp;&emsp;Local模式是单机运行（HDFS，Yarn均有此模式），通常用于测试，Spark程序以多线程的方式运行在单台主机上。

&emsp;&emsp;Standalone模式下，Spark集群独立运行，不依赖于第三方资源管理系统，采用主从架构，Driver运行在Worker中，Master只负责集群管理。可用ZooKeeper来实现HA-Spark。


<p align="center">
    <img src="/pic/3/3-15 Spark Standalone模式.png" width="50%">
    <br/>
    <em>3-15 Spark Standalone模式.png</em>
</p>

&emsp;&emsp;Yarn模式下，Driver被包裹在ApplicationMaster中，客户向ResourceManager提交Spark程序，ResourceManager会为该程序创建一个包含管理该作业Driver的ApplicationMaster，Driver通过AM向ResourceManager申请Container，最后将任务分配给Container执行，其过程和执行MapReduce作业高度类似，从这也可以看出为什么说Yarn提供了统一的资源管理服务，其成为了Spark和Hadoop的桥梁。


<p align="center">
    <img src="/pic/3/3-17 Spark Yarn模式.png" width="50%">
    <br/>
    <em>3-17 Spark Yarn模式.png</em>
</p>

### 3.4.5 总结

&emsp;&emsp;本节从MapReduce的缺点说起，引出了Spark产生的原因，进一步介绍了Spark中的核心数据结构RDD，RDD可以进行丰富的操作来表达各种复杂的任务，这造就了Spark的灵活性。Spark的架构和Yarn高度相似，作业启动的做法也如出一辙；通过Yarn，Spark可以和Hadoop集成在一起。在下节内容中，我们将小试牛刀，从安装Spark讲起，将其与之前搭建的Hadoop连接，最后和MapReduce类似，我们会编写一个单词计数小程序。
