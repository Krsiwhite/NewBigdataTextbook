## 3.1 MapReduce介绍

&emsp;&emsp;MapReduce是Hadoop生态的核心组件之一，MapReduce是一个批处理框架，其依赖于HDFS的存储技术，在其背后有多种含义：

1. Hadoop生态的核心组件
2. 解决大数据并行计算的编程思想

&emsp;&emsp;可以简单理解为MapReduce组件应用了MapReduce的编程思想，主要目的是解决利用集群解决大数据并行计算的问题。那么想要介绍MapReduce，首先应该介绍的就是其背后的编程思想。但在此之前，还是有必要稍微说一下为什么MapReduce如此重要以及他的发展历程。

### 3.1.1 MapReduce的历史地位

&emsp;&emsp;MapReduce是解决大数据并行计算的编程思想，那么什么是大数据并行计算呢？我们在前面也提到过，大数据之所以为“大”就是因为如此规模的数据已经大大超出了一台主机的处理能力，这种“大任务”必须切割成多个较小的任务分配到不同的主机上去完成，什么是“并行”呢？就是指所有这些主机是在同时处理这些小任务，这听起来似乎很简单，好像和常见的——开一个循环遍历所有主机，每个主机跑一个单开的进程也没什么大的不同。但一旦落到实际，就远没有看起来的那么简单，首先我们如何去切分“大任务”，是把一道菜按照工序切分，每个人完成不同部分；还是按照菜量分配，每个人炒同一道菜的一小部分？当主机A的任务需要用到主机B的任务结果时，怎么去协调？在这其中，我们面临着许多或大或小的问题，当然也有着许多不同的解决问题的思路，而MapReduce可以认为是一个较好的一套解决方案。马里兰大学教授、2010年出版的《Data-Intensive Text Processing with MapReduce》一书的作者Jimmy Lin在书中提出：
>MapReduce改变了我们组织大规模计算的方式，它代表了第一个有别于冯·诺依曼结构的计算模型，是在集群规模而非单个机器上组织大规模计算的新的抽象模型上的第一个重大突破，是到所见到的最为成功的基于大规模计算资源的计算模型。

&emsp;&emsp;可以说，MapReduce的推出给大数据并行处理带来了巨大的革命性影响，使其已经成为事实上的大数据处理的工业标准。尽管MapReduce还有很多局限性（并不能将所有单机任务都使用MapReduce并行化），但人们普遍公认，MapReduce是到目前为止最为成功、最广为接受和最易于使用的大数据并行处理技术。MapReduce的发展普及和带来的巨大影响都远远超出了发明者和开源社区当初的意料。

### 3.1.2 MapReduce的发展历程

&emsp;&emsp;MapReduce最早是由Google公司研究提出的一种面向大规模数据处理的并行计算模型和方法。Google公司设计MapReduce的初衷主要是为了解决其搜索引擎中大规模网页数据的并行化处理。Google公司发明了MapReduce之后首先用其重新改写了其搜索引擎中的Web文档索引处理系统。但由于MapReduce可以普遍应用于很多大规模数据的计算问题，因此自发明MapReduce以后，Google公司内部进一步将其广泛应用于很多大规模数据处理问题。Google公司内有上万个各种不同的算法问题和程序都使用MapReduce进行处理。

&emsp;&emsp;2003年和2004年，Google公司在国际会议上分别发表了两篇关于Google分布式文件系统和MapReduce的论文，Google的那篇MapReduce论文里说：
>Our abstraction is inspired by the map and reduce primitives present in Lisp and many other functional languages。

&emsp;&emsp;这句话提到了MapReduce思想的渊源，大致意思是，MapReduce的灵感来源于函数式语言（比如Lisp）中的内置函数map和reduce。

&emsp;&emsp;2004年，开源项目Lucene（搜索索引程序库）和Nutch（搜索引擎）的创始人Doug Cutting发现MapReduce正是其所需要的解决大规模Web数据处理的重要技术，因而模仿Google MapReduce，基于Java设计开发了一个称为Hadoop的开源MapReduce并行计算框架和系统。自此，Hadoop成为Apache开源组织下最重要的项目，自其推出后很快得到了全球学术界和工业界的普遍关注，并得到推广和普及应用。

### 3.1.3 MapReduce的编程思想

&emsp;&emsp;MapReduce的并行计算可分为三个阶段：

1. Map
2. Shuffle
3. Reduce
   
&emsp;&emsp;可以把MapReduce理解为，把一堆杂乱无章的数据按照某种特征归纳起来，然后处理并得到最后的结果。Map面对的是杂乱无章的互不相关的数据，它解析每个数据，从中提取出Key和Value，也就是提取了数据的特征。经过MapReduce的Shuffle阶段之后，在Reduce阶段看到的都是已经归纳好的数据了，在此基础上我们可以做进一步的处理以便得到结果。

&emsp;&emsp;以上是比较抽象的关于MapReduce思想的解释，你可以能会感到非常的困惑，为什么会去提到Key和Value，这和MapReduce有什么关系？为什么Map面对的是杂乱无章的数据，而Reduce阶段看到的都是已经归纳好的数据？别着急，现在让我们举一个例子，这是所有MapReduce初学者都会听说过的一个问题——单词计数。

&emsp;&emsp;我们先来描述一下单词计数问题：现在有一个文本文件，其全部由英文写成（可以想象其为一英语大部头著作），现在的任务是将其中所有单词的频度（也就是出现次数）进行统计并输出。这是一个很简单的任务，总的来说：你首先需要剔除掉文本中的一些标点符号，在这之后整个文本文件里就只剩下了空格、换行符和单词，经过预处理后再用空格分隔每行的字符串便能得到一个个的单词，剩下的工作就是统计而已。

&emsp;&emsp;当你需要处理的文本只有几MB大小时，使用任意一个编程语言在现代机器上很快就能跑完，但如果你要处理的文本很大，例如你想统计整个公司客服所产生的所有和用户的聊天记录中各单词出现的频率，以此来找到用户最关心哪些问题，在这样的场景中整个文本文件可能就会以GB计了。此时再使用一台主机处理恐怕就需要花费较长时间，更进一步，如果你的公司每天都产生比这多得多的日志，那就更不可能单机处理。

&emsp;&emsp;那如何使用MapReduce的思想来解决这个问题呢？在开始之前，请大家记住整个MapReduce所作的事情就是将原始数据转换为一堆键值对，对这些键值对不断操作最终产生结果所需的另一堆键值对。

```
                [K1, V1]  op           output   
origin data --> [K1, V1] ----> ... -> [Kn, Vn]
                [K1, V1]              [Kn, Vn]
                 ......                ......
```

**（1）Map阶段**

&emsp;&emsp;首先原始数据还不能直接进入Map阶段，我们需要将其转换为Map能处理的格式，这个过程叫`InputFormat`。其主要作用是将输入数据切分为符合 Map 需求的切片（file split）。根据不同的数据源会有不同的`InputFormat`实现。常见的`InputFormat`实现有：

* `TextInputFormat`：用于处理纯文本数据。
* `FileInputFormat`：用于处理文件数据。
* `KeyValueTextInputFormat`：用于处理键值对格式的文本文件。
* `DBInputFormat`：用于处理数据库表数据。


&emsp;&emsp;因此，我们此时会选用`TextInputFormat`来处理数据，具体来说，`InputFormat`会将整个文件切分成一个个的切片，接着规格化切片中的格式，`TextInputFormat`中将每一行作为一个键值对，Key是该行在整个文件中的字节偏移量，Value则是该行行所对应的字符串。如图3-2所示。这可以算作是最初始的键值对，我们把如此格式切分后的值称为`<K1, V1>`。

<p align="center">
    <img src="/pic/3/3-2 TextInputFormat.png" width="50%">
    <br/>
    <em>图3-2 TextInputFormat</em>
</p>


&emsp;&emsp;接着每个切片（在这里每个切片包含多个如上图所示的键值对）会进入一个叫做MapTask的结构继续处理，在其中我们会去提取数据的特征，此时我们需要编写一个`Mapper`方法，用该方法去处理经过`TextInputFormat`后得到的`<K1, V1>`键值对，将其转换为另一不同格式的键值对`<K2, V2>`。在此任务中我们只需要将前面提取出的每行字符串进一步切分为一个个的单词即可，因为涉及到的是单词计数，我们便将Key设置为该单词，Value设置为1代表该单词在此出现一次。以下展示了一个包含三个键值对的切片经过MapTask后的结果。  

```
<0, Hello Hadoop>              Mapper    <hello, 1>   
<12, I am a big data learner>  ----->    <i,     1> 
<35, this is so amazing>                 <Hadoop,1>
                                         <data,  1>
                                         ......                
```

**（2）Shuffle阶段**

&emsp;&emsp;当MapTask任务执行完成后，Map阶段处理的数据将重新改组传递到Reducer阶段处理，这个过程叫做Shuffle。在该阶段要完成的工作简述如下：

1. 对输出的 Key-Value 对进行分区
2. 对不同分区的数据按照相同的 Key 排序
3. 对数据进行分组, 相同 Key 的 Value 放入一个集合中
   

&emsp;&emsp;我们一步一步来看，首先在第一步分区的含义是指有些时候我们相将任务的结果根据需求划分成不同的部分，例如我想：

1. 单独统计单词长度小于5的单词出现的频度
2. 单独统计单词长度大于5的单词出现的频度

&emsp;&emsp;我们可以将MapTask得到的`<K2, V2>`依据K2的长度分成两个不同的分区，将他们分别发送给不同的ReduceTask。在第二步中，我们会将处于相同分组的数据按照Key的字典序进行排序。在第三步，具有相同Key的键值对会被聚合在一起，形成新的`<K2, V2>`，在Shuffle前后K2的值保持不变，而新形成的V2是Map输出结果键值对（即`<K2, V2>`）中所有相同K2对应的值V2组成的集合：

```
<hadoop, 1>          
<hello, 1>           <hadoop, [1, 1]>
<hadoop, 1>   ---->  <hello,  [1, 1]>
<hello, 1>
```

**（3）Reduce阶段**

&emsp;&emsp;每个分区的数据会由一个ReduceTask处理，有多少个分区就有多少个ReduceTask。ReduceTask接受Shuffle阶段产生的键值对`<K2, V2>`，对其进行用户自定义的处理逻辑，最终结果同样以键值对的方式输出为`<K3, V3>`，经过以上（1），（2）步骤后，在这里每个单词就对应着一个键值对，键值对的值为一个集合，其中的元素全为1，而该集合的大小就对应着该单词在文本中出现的次数。故在Reduce阶段我们只需对每一个键值对的Value进行求和即可，Key保持不变，那么得到的`<K3, V3>`就代表单词K3出现的次数V3。

```      
                              output 
<hello, [1, 1]>   reduce     <hello,  2>
<hadoop, [1, 1]>  ------>    <hadoop, 4>
.....                           ......
```

&emsp;&emsp;通过单词计数的例子，相信你已经了解了MapReduce的工作方式，总结来说，MapReduce的构思如下：



<p align="center">
    <img src="/pic/3/3-3 MapReduce工作流程概述.png" width="50%">
    <br/>
    <em>图3-3 MapReduce工作流程概述</em>
</p>

**（1）分而治之**

&emsp;&emsp;对相互间不具有计算依赖关系的大数据，实现并行最自然的办法就是采取分而治之的策略。并行计算的第一个重要问题是如何划分计算任务或者计算数据以便对划分的子任务或数据块同时进行计算。不可分拆的计算任务或相互间有依赖关系的数据无法进行并行计算！单词计数便是这种不具有依赖关系的大数据，对每行单词做统计和其他行完全无关，但倘若你想分析的是每句对话是由哪个角色说出的，这样行和行之间就有了依赖关系，也就无法使用MapReduce完成了。

**（2）统一构架，隐藏系统层细节**

&emsp;&emsp;如何提供统一的计算框架，如果没有统一封装底层细节，那么程序员则需要考虑诸如数据存储、划分、分发、结果收集、错误恢复等诸多细节；为此，MapReduce设计并提供了统一的计算框架，为程序员隐藏了绝大多数系统层面的处理细节。

&emsp;&emsp;MapReduce最大的亮点在于通过抽象模型和计算框架把需要做什么(what need to do)与具体怎么做(how to do)分开了，为程序员提供一个抽象和高层的编程接口和框架。程序员仅需要关心其应用层的具体计算问题，仅需编写少量的处理应用本身计算问题的程序代码。如何具体完成这个并行计算任务所相关的诸多系统层细节被隐藏起来,交给计算框架去处理：从分布代码的执行，到大到数千小到单个节点集群的自动调度使用。总的来说，在一般情况下程序员编写MapReduce程序只需要考虑这几件事：

1. 设定`InputFormat`如何对数据切片，产生`<K1, V1>`。
2. 设计MapTask，`<K1, V1> --> <K2, V2>`。
3. 设定如何分区（也可不做，则默认所有数据一个分区），聚合`<K2, V2>`。
4. 设计ReduceTask，`<K2, V2> --> <K3, V3>`。
5. 设定`OutputFormat`，得到最终结果文件。

### 3.1.4 总结

&emsp;&emsp;我们已经从思想上完全了解了MapReduce，那么接下来要学习的便是MapReduce实践，在后续的内容中，我们会带领大家完成编写一个简单的MapReduce任务，同时更具体地去学习MapReduce实际上的整个运行逻辑。但在此之前，我们需要先学习Hadoop中的另一个核心组件——Yarn。