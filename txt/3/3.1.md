## 3.1 MapReduce介绍

&emsp;&emsp;MapReduce是Hadoop生态的核心组件之一，MapReduce是一个批处理框架，其依赖于HDFS的存储技术，在其背后有多种含义：

1. Hadoop生态的核心组件
2. 解决大数据并行计算的编程思想

&emsp;&emsp;可以简单理解为MapReduce组件应用了MapReduce的编程思想，主要目的是解决利用集群解决大数据并行计算的问题。那么想要介绍MapReduce，首先应该介绍的就是其背后的编程思想。但在此之前，还是有必要稍微说一下为什么MapReduce如此重要以及他的发展历程。

### 3.1.1 MapReduce的历史地位

&emsp;&emsp;MapReduce是解决大数据并行计算的编程思想，那么什么是大数据并行计算呢？我们在前面也提到过，大数据之所以为“大”就是因为如此规模的数据已经大大超出了一台主机的处理能力，这种“大任务”必须切割成多个较小的任务分配到不同的主机上去完成，什么是“并行”呢？就是指所有这些主机是在同时处理这些小任务，这听起来似乎很简单，好像和常见的——开一个循环遍历所有主机，每个主机跑一个单开的进程也没什么大的不同。但一旦落到实际，就远没有看起来的那么简单，首先我们如何去切分“大任务”，是把一道菜按照工序切分，每个人完成不同部分；还是按照菜量分配，每个人炒同一道菜的一小部分？当主机A的任务需要用到主机B的任务结果时，怎么去协调？在这其中，我们面临着许多或大或小的问题，当然也有着许多不同的解决问题的思路，而MapReduce可以认为是一个较好的一套解决方案。马里兰大学教授、2010年出版的《Data-Intensive Text Processing with MapReduce》一书的作者Jimmy Lin在书中提出：
>MapReduce改变了我们组织大规模计算的方式，它代表了第一个有别于冯·诺依曼结构的计算模型，是在集群规模而非单个机器上组织大规模计算的新的抽象模型上的第一个重大突破，是到所见到的最为成功的基于大规模计算资源的计算模型。

&emsp;&emsp;可以说，MapReduce的推出给大数据并行处理带来了巨大的革命性影响，使其已经成为事实上的大数据处理的工业标准。尽管MapReduce还有很多局限性（并不能将所有单机任务都使用MapReduce并行化），但人们普遍公认，MapReduce是到目前为止最为成功、最广为接受和最易于使用的大数据并行处理技术。MapReduce的发展普及和带来的巨大影响都远远超出了发明者和开源社区当初的意料。

### 3.1.2 MapReduce的发展历程

&emsp;&emsp;MapReduce最早是由Google公司研究提出的一种面向大规模数据处理的并行计算模型和方法。Google公司设计MapReduce的初衷主要是为了解决其搜索引擎中大规模网页数据的并行化处理。Google公司发明了MapReduce之后首先用其重新改写了其搜索引擎中的Web文档索引处理系统。但由于MapReduce可以普遍应用于很多大规模数据的计算问题，因此自发明MapReduce以后，Google公司内部进一步将其广泛应用于很多大规模数据处理问题。Google公司内有上万个各种不同的算法问题和程序都使用MapReduce进行处理。

&emsp;&emsp;2003年和2004年，Google公司在国际会议上分别发表了两篇关于Google分布式文件系统和MapReduce的论文，Google的那篇MapReduce论文里说：
>Our abstraction is inspired by the map and reduce primitives present in Lisp and many other functional languages。

&emsp;&emsp;这句话提到了MapReduce思想的渊源，大致意思是，MapReduce的灵感来源于函数式语言（比如Lisp）中的内置函数map和reduce。

&emsp;&emsp;2004年，开源项目Lucene（搜索索引程序库）和Nutch（搜索引擎）的创始人Doug Cutting发现MapReduce正是其所需要的解决大规模Web数据处理的重要技术，因而模仿Google MapReduce，基于Java设计开发了一个称为Hadoop的开源MapReduce并行计算框架和系统。自此，Hadoop成为Apache开源组织下最重要的项目，自其推出后很快得到了全球学术界和工业界的普遍关注，并得到推广和普及应用。

### 3.1.3 MapReduce的编程思想

&emsp;&emsp;MapReduce的并行计算可分为三个阶段：

1. Map
2. Shuffle
3. Reduce
   
&emsp;&emsp;可以把MapReduce理解为，把一堆杂乱无章的数据按照某种特征归纳起来，然后处理并得到最后的结果。Map面对的是杂乱无章的互不相关的数据，它解析每个数据，从中提取出Key和Value，也就是提取了数据的特征。经过MapReduce的Shuffle阶段之后，在Reduce阶段看到的都是已经归纳好的数据了，在此基础上我们可以做进一步的处理以便得到结果。

&emsp;&emsp;以上是比较抽象的关于MapReduce思想的解释，你可以能会感到非常的困惑，为什么会去提到Key和Value，这和MapReduce有什么关系？为什么Map面对的是杂乱无章的数据，而Reduce阶段看到的都是已经归纳好的数据？别着急，现在让我们举一个例子，这是所有MapReduce初学者都会听说过的一个问题——单词计数。

&emsp;&emsp;我们先来描述一下单词计数问题：现在有一个文本文件，其全部由英文写成（可以想象其为一英语大部头著作），现在的任务是将其中所有单词的频度（也就是出现次数）进行统计并输出。这是一个很简单的任务，总的来说：你首先需要剔除掉文本中的一些标点符号，在这之后整个文本文件里就只剩下了空格、换行符和单词，经过预处理后再用空格分隔每行的字符串便能得到一个个的单词，剩下的工作就是统计而已。

&emsp;&emsp;当你需要处理的文本只有几MB大小时，使用任意一个编程语言在现代机器上很快就能跑完，但如果你要处理的文本很大，例如你想统计整个公司客服所产生的所有和用户的聊天记录中各单词出现的频率，以此来找到用户最关心哪些问题，在这样的场景中整个文本文件可能就会以GB计了。此时再使用一台主机处理恐怕就需要花费较长时间，更进一步，如果你的公司每天都产生比这多得多的日志，那就更不可能单机处理。

&emsp;&emsp;那如何使用MapReduce的思想来解决这个问题呢？在开始之前，请大家记住整个MapReduce所作的事情就是将原始数据转换为一堆键值对，对这些键值对不断操作最终产生结果所需的另一堆键值对。

```
                [K1, V1]  op           output   
origin data --> [K1, V1] ----> ... -> [Kn, Vn]
                [K1, V1]              [Kn, Vn]
                 ......                ......
```

**（1）Map阶段**

&emsp;&emsp;首先原始数据还不能直接进入Map阶段，我们需要将其转换为Map能处理的格式，这个过程叫`InputFormat`。其主要作用是将输入数据切分为符合 Map 需求的切片（file split）。根据不同的数据源会有不同的`InputFormat`实现。常见的`InputFormat`实现有：

* `TextInputFormat`：用于处理纯文本数据。
* `FileInputFormat`：用于处理文件数据。
* `KeyValueTextInputFormat`：用于处理键值对格式的文本文件。
* `DBInputFormat`：用于处理数据库表数据。


&emsp;&emsp;因此，我们此时会选用`TextInputFormat`来处理数据，具体来说，其会将每一行作为一个键值对，Key是改行在整个文件中的字节偏移量，Value则是改行所对应的字符串。
```


```


接着在Map阶段我们会去提取数据的特征，在此任务中我们只需要将



