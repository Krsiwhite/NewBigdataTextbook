## 2.3 ZooKeeper：分布式系统的协调者
&emsp;&emsp;Zookeeper是一个开源的分布式协调服务，由Apache基金会开发和维护，主要用于分布式系统的协调管理和通信，其最初是作为Hadoop项目的一部分开发的，目的是解决分布式系统中常见的协调问题，如数据同步、配置管理等。随着分布式系统的发展，Zookeeper逐渐成为一个独立的项目，并被广泛应用于各种分布式系统架构中。

&emsp;&emsp;试想一下，你的餐厅后厨有一名大厨和一名学徒，大厨负责后厨的工作，学徒每天刻苦努力地跟着大厨学习，突然有一天，大厨工作到一半家里有事请假了，那此时作为餐厅老板的你是不是应该马上让学徒接管大厨的工作，继续维持后厨的正常运行呢？其实ZooKeeper在分布式系统中，就是起到这么一个作用，当某节点出现故障时，让其他节点接替故障节点的工作，保障分布式系统的正常运行，这样的一种特性就叫做高可用性（High Available, HA）。目前，ZooKeeper已被大量开源的分布式系统采用，包括HDFS、YARN、HBase等，本节将通过实验来向大家演示ZooKeeper是如何实现高可用性的，你可以记住上述大厨和学徒的场景与ZooKeeper的高可用性类比学习以加深理解。

### 2.3.1 ZooKeeper与HDFS

&emsp;&emsp;在HDFS中，NameNode负责管理文件系统的元数据，是整个HDFS的核心，存储了整个文件系统的目录结构等，它就像后厨场景中的大厨，负责后厨正常运行，如果NameNode所在的机器发生故障，那么整个分布式系统将出现问题，对于这种在一个系统中，由于某一部件的故障，导致整个系统或网络无法正常工作的情况，叫做单点故障（Single Point of Failure）。


&emsp;&emsp;我们可以通过 ZooKeeper 实现NameNode的高可用性，ZooKeeper集群会和 HDFS 集群协同工作：HDFS集群中会同时存在多个 NameNode节点，但只有一个是在真正工作的活跃（Active）状态，其他都处于待命（Standby）状态，这些待命状态的NameNode节点会不断的与活跃状态的NameNode节点进行同步。当Active的NameNode节点故障时，通过与ZooKeeper集群的协作，会将一个Standby的NameNode节点转变为Active来继续工作，从而避免单点故障，实现了高可用性。实现了高可用性的HDFS我们就可以称之为HA-HDFS（High Available HDFS），接下来我们将配置ZooKeeper集群，同时修改 HDFS 集群相关配置使二者协同工作，从而实现HA-HDFS。

&emsp;&emsp;在正式开始前，我们首先给要完成的操作列个清单：

1. 安装与配置ZooKeeper  
2. 单独验证ZooKeeper集群
3. 初始化HA-HDFS配置
4. 首次启动HA-HDFS
5. 再次启动HA-HDFS
6. 验证HA-HDFS高可用性


**（1）安装与配置ZooKeeper**

_先在m1主机进行如下安装与配置，完成后同步到主机m2和m3_

&emsp;&emsp;本书实验采用ZooKeeper的3.8.4版本，我们可以从清华镜像源获取下载，下载在`/root`目录下。

&emsp;&emsp;`wget https://mirrors.tuna.tsinghua.edu.cn/apache/zookeeper/zookeeper-3.8.4/apache-zookeeper-3.8.4-bin.tar.gz`

&emsp;&emsp;接着将其解压到当前目录即可。

&emsp;&emsp;`tar -zxvf apache-zookeeper-3.8.4-bin.tar.gz`

&emsp;&emsp;为了统一各组件的命令，我们将该文件夹修改为`zookeeper-3.8.4`：

&emsp;&emsp;`mv apache-zookeeper-3.8.4-bin zookeeper-3.8.4`
 
&emsp;&emsp;接下来我们需要为安装的ZooKeeper创建`zoo.cfg`配置文件，将`zookeeper-3.8.4/conf`中提供的`zoo_sample.cfg`模板复制一份并将其重命名为`zoo.cfg`。

&emsp;&emsp;`cp /root/zookeeper-3.8.4/conf/zoo_sample.cfg /root/zookeeper-3.8.4/conf/zoo.cfg`

&emsp;&emsp;修改配置文件，在其中我们需要填入集群各主机信息。主机信息的配置格式为server.A=B:C:D。

* 其中A表示服务器编号；
* B代表该服务器的地址，这里设定为m1、m2和m3的原因是我们设置过ip地址的映射；
* C指定了该服务器Follower与集群中的Leader服务器交换信息的端口；
* D指定了执行选举时服务器间相互通信的端口，当集群中的Leader节点产生故障时，需要该端口来重新选举一个新的Leader。

```
server.1=m1:2888:3888
server.2=m2:2888:3888
server.3=m3:2888:3888
```

&emsp;&emsp;编辑环境变量⽂件/etc/profile，文件尾部加⼊以下配置。
```
dataDir=/root/zookeeper-3.8.4/data
export ZK_HOME=/root/zookeeper-3.8.4
export PATH=$PATH:$ZK_HOME/bin
```

&emsp;&emsp;将环境变量和zookeeper目录同步到主机m2和m3。
```shell
scp -r /root/zookeeper-3.8.4 m2:/root 
scp -r /root/zookeeper-3.8.4 m3:/root 
scp -r /etc/profile m2:/etc
scp -r /etc/profile m3:/etc
```

&emsp;&emsp;在三台主机上重新加载环境变量。

&emsp;&emsp;`source /etc/profile`


_主机m1执行下面的命令_

&emsp;&emsp;将1写入`myid`文件，设置主机m1投票编号为1。

&emsp;&emsp;`echo 1 >> /root/zookeeper-3.8.4/data/myid`

_主机m2执行下面的命令_

&emsp;&emsp;将2写入`myid`文件，设置主机m2的投票编号为2。

&emsp;&emsp;`echo 2 >> /root/zookeeper-3.8.4/data/myid`

_主机m3执行下面的命令_

&emsp;&emsp;将3写入`myid`文件，设置主机m3的投票编号为3。

&emsp;&emsp;`echo 3 >> /root/zookeeper-3.8.4/data/myid`

**（2）单独验证ZooKeeper集群**

_三台主机都需要执行如下命令_

&emsp;&emsp;执行如下命令开启ZooKeeper.

&emsp;&emsp;`zkServer.sh start`

&emsp;&emsp;在各主机查看ZooKeeperk状态，发现其中有一台主机为Leader，另外两台主机为Follower。

&emsp;&emsp;`zkServer.sh status`

```
root@m1:~# zkServer.sh status
ZooKeeper JMX enabled by default
Using config: /root/zookeeper-3.8.4/bin/../conf/zoo.cfg
Client port found: 2181. Client address: localhost. Client SSL: false.
Mode: follower
```

``` 
root@m2:~# zkServer.sh status
ZooKeeper JMX enabled by default
Using config: /root/zookeeper-3.8.4/bin/../conf/zoo.cfg
Client port found: 2181. Client address: localhost. Client SSL: false.
Mode: leader
```

```
root@m3:~# zkServer.sh status
ZooKeeper JMX enabled by default
Using config: /root/zookeeper-3.8.4/bin/../conf/zoo.cfg
Client port found: 2181. Client address: localhost. Client SSL: false.
Mode: follower
```

&emsp;&emsp;验证后使用如下命令关闭ZooKeeper集群。

&emsp;&emsp;`zkServer.sh stop`
 
**（3）初始化HA-HDFS配置**

_三台主机都需要执行如下操作_

&emsp;&emsp;全新的Haddoop集群，需删除原先的`data`目录和`logs`目录。
```
rm -rf /root/hdfs
rm -rf /root/hadoop-3.3.6/logs
```

_主机m1执行如下操作_

&emsp;&emsp;修改`/root/hadoop-3.3.6/etc/hadoop/core-site.xml`中内容为：

```
<configuration>
    <!--hdfs入口，设置虚拟地址，具体地址后面配置-->
    <property>
        <name>fs.defaultFS</name>
        <value>hdfs://hdfs-cluster</value>
    </property>
  <!-- HDFS web loggin static user -->
  <property>
    <name>hadoop.http.staticuser.user</name>
    <value>bigdata_chef</value>
  </property> 
    <!--hdfs要访问zookeeper集群-->
    <property>
        <name>ha.zookeeper.quorum</name>
        <value>m1:2181,m2:2181,m3:2181</value>
    </property>
</configuration>
```

&emsp;&emsp;修改`/root/hadoop-3.3.6/etc/hadoop/hdfs-site.xml`中内容为：

```
<configuration>
    <property>
    <name>dfs.name.dir</name>
    <value>/root/hdfs/namenode</value>
    </property>
    <property>
    <name>dfs.data.dir</name>
    <value>/root/hdfs/datanode</value>
    </property>
    <!-- 副本数 -->
    <property>
        <name>dfs.replication</name>
        <value>3</value>
    </property>
    <!-- 定义dhfs入口的命名服务 -->
    <property>
        <name>dfs.nameservices</name>
        <value>hdfs-cluster</value>
    </property>
    <!-- 定义hdfs入口的命名服务下虚拟ip-->
    <property>
        <name>dfs.ha.namenodes.hdfs-cluster</name>
        <value>nn1,nn2</value>
    </property>
    <!-- 虚拟ip地址1 RPC入口 -->
    <property>
        <name>dfs.namenode.rpc-address.hdfs-cluster.nn1</name>
        <value>m1:9000</value>
    </property>
    <!-- 虚拟ip地址1 HTTP入口 -->
    <property>
        <name>dfs.namenode.http-address.hdfs-cluster.nn1</name>
        <value>m1:50070</value>
    </property>
    <!-- 虚拟ip地址2 PRC入口 -->
    <property>
        <name>dfs.namenode.rpc-address.hdfs-cluster.nn2</name>
        <value>m2:9000</value>
    </property>
    <!-- 虚拟ip地址1 HTTP入口 -->
    <property>
        <name>dfs.namenode.http-address.hdfs-cluster.nn2</name>
        <value>m2:50070</value>
    </property>
    
    <!-- 定义QJN在linux中保存文件磁盘目录 -->
    <property>
        <!-- Journal Edit Files 的存储目录:() -->
        <name>dfs.journalnode.edits.dir</name>
        <value>/root/journalnode/data/</value>
    </property>
    <!-- namenode要向zk的QJN写入editslog，所以要明确入口地址 -->
    <property>
        <name>dfs.namenode.shared.edits.dir</name>
        <value>qjournal://m1:8485;m2:8485;m3:8485/hdfs-cluster</value>
    </property>

    <!-- 是否开启故障切换 -->
    <property>
        <name>dfs.ha.automatic-failover.enabled</name>
        <value>true</value>
    </property>

    <!-- 基于zookeeper的故障切换的代码类 -->
    <property>
        <name>dfs.client.failover.proxy.provider.hdfs-cluster</name>
    <value>org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider</value>
    </property>
    
    
    <!-- 远程杀死namenode方式(防止namenode假死，导致双主出现) -->
    <property>
        <name>dfs.ha.fencing.methods</name>
        <value>shell(/bin/true)</value>
    </property>
    
    <!-- 指定私钥的文件目录，使用免密登录杀死NN进程 -->
    <property>
        <name>dfs.ha.fencing.ssh.private-key-files</name>
        <value>/root/.ssh/id_rsa</value>
    </property> 
</configuration>
```

&emsp;&emsp;修改`/root/hadoop-3.3.6/sbin/hadoop-env.sh`，在末尾追加以下内容，为两个新增节点设置启动用户为`root`：

```
HDFS_ZKFC_USER="root"
HDFS_JOURNALNODE_USER="root"
```

&emsp;&emsp;将配置分发到其他节点。
```shell
scp  -r  /root/hadoop-3.3.6/etc/hadoop root@m2:/root/hadoop-3.3.6/etc/
scp  -r  /root/hadoop-3.3.6/etc/hadoop root@m3:/root/hadoop-3.3.6/etc/
```

**（4）首次启动HA-HDFS**

_三台主机都需要执行如下操作_

&emsp;&emsp;3台主机启动ZooKeeper集群：

&emsp;&emsp;`zkServer.sh start`

_主机m1执行如下操作_

&emsp;&emsp;执行初始化ZKFC在ZooKeeper中的Znode信息：

&emsp;&emsp;`hdfs zkfc -formatZK`


_三台主机都需要执行如下操作_

&emsp;&emsp;启动journalnode（QJN将作为NameNode存储持久化文件的空间，要先启动才能格式化）。

&emsp;&emsp;`hdfs --daemon start journalnode`

_主机m1执行如下操作_

&emsp;&emsp;格式化NameNode主机，`hdfs namenode -format`，而后启动整个HDFS集群，`start-dfs.sh`。

_主机m2执行如下操作_

&emsp;&emsp;声明此机器为NameNode备机。

&emsp;&emsp;`hdfs namenode -bootstrapStandby`

&emsp;&emsp;启动NameNode备机。

&emsp;&emsp;`hdfs --daemon start namenode`

&emsp;&emsp;到此我们就初始化好了HA-HDFS。

**（5）再次启动HA-HDFS**

&emsp;&emsp;经过首次启动并初始化后，我们已经搭建好了HA-HDFS。之后的启动过程如下：

&emsp;&emsp;首先关闭在（4）中初始化好的HA-HDFS。关闭时，使用`stop-dfs.sh`命令关闭HA-Hadoop集群。

&emsp;&emsp;而后，使用`zkServer.sh stop`命令关闭主机中的ZooKeeper集群相关节点，在所有主机上执行以关闭ZooKeeper集群，至此完整关闭了HA-HDFS，在今后若要关闭HDFS集群，使用命令同上。

&emsp;&emsp;在今后的启动中，执行命令如下：首先在集群所有主机中执行`zkServer.sh start`启动ZooKeeper集群。而后在一主机上执行`start-dfs.sh`以启动HA-HDFS。

&emsp;&emsp;若配置正确，此时我们在m1、m2和m3使用`jps`命令，结果如下：

```
root@m1:~/hadoop-3.3.6/sbin# jps
143137 Jps
142548 DataNode
142186 QuorumPeerMain
143017 DFSZKFailoverController
142399 NameNode
142780 JournalNode
```

```
root@m2:~# jps
133584 Jps
133489 DFSZKFailoverController
133078 NameNode
133191 DataNode
133319 JournalNode
132939 QuorumPeerMain
```

```
root@m3:~# jps
136770 DataNode
136898 JournalNode
137029 Jps
136639 QuorumPeerMain
```

**（6）验证HA-HDFS高可用性**

&emsp;&emsp;在2.2节中，只有`m1`是NameNode，而此时我们`m1`和`m2`均为NameNode，`m2`即为`m1`的备用节点，按照高可用性的说法，此时如果我们关闭`m1`主机上的NameNode进程，那么`m2`中的NameNode会接替`m1`。接下来让我们验证一下。

_主机m3执行如下操作_

&emsp;&emsp;查看`m1`主机和`m2`主机节点的状态，发现`m1`主机的节点状态为active，`m2`主机的节点状态为standby，也就是说，此时`m1`为真正工作的节点，也就是真正炒菜的厨师，而`m2`处于待机状态，随时准备接替工作。

&emsp;&emsp;`hdfs haadmin -getServiceState nn1`

&emsp;&emsp;`hdfs haadmin -getServiceState nn2`

```
root@m1:~# hdfs haadmin -getServiceState nn1
active
root@m1:~# hdfs haadmin -getServiceState nn2
standby
```

&emsp;&emsp;现在，关闭`m1`上的NameNode节点，模拟NameNode的Active节点出现故障。

&emsp;&emsp;`hdfs --daemon stop namenode`，再使用`jps`命令，可见该主机上的NameNode进程已关闭。

```
root@m1:~# jps
144561 Jps
142548 DataNode
142186 QuorumPeerMain
143017 DFSZKFailoverController
142780 JournalNode
```

_主机m3执行如下操作_

&emsp;&emsp;查看m1主机和m2主机节点的状态，发现m1主机的节点状态无法查看，m2主机的节点状态为active，这说明备用节点接替了主节点的工作。

```shell
root@m1:~# hdfs haadmin -getServiceState nn1
2025-05-18 12:15:55,525 INFO ipc.Client: Retrying connect to server: m1/192.168.0.2:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=1, sleepTime=1000 MILLISECONDS)
Operation failed: Call From 0003/0.0.0.3 to m1:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused

root@m1:~# hdfs haadmin -getServiceState nn2
active
```

### 2.3.2 HA的背后原理

&emsp;&emsp;经过2.3.1节的部署，我们已经拥有了一个HA-HDFS集群。简单来说，HA集群只实现了一件事：部署多个NameNode节点，主NameNode宕机时，其余的节点立刻补上；或者说，聘请多个厨师，只有一个在炒菜，但要求该厨师请假时旁边的厨师要能马上接着干活。要实现这个目的，我们需要考虑两件事：

* 如何得知Active的NameNode宕机了，得知其宕机后如何通知另一个NameNode接替？
* NameNode节点存储了元数据（见2.2），不同主机上的NameNode如何保持目录结构等数据的一致？


&emsp;&emsp;要解答这两个关键问题，就要去关注集群中增加了什么。在2.3.1的步骤（6）中，我们可以看到集群中的每台主机都新增了多个不同作用的节点，他们分别是：

* JournalNode
* QuorumPeerMain
* DFSZKFailoverController

&emsp;&emsp;三种新增的节点必然不是无缘无故产生的，他们同实现 HA 理应有着不可分割的联系。接下来就让我们看看他们是如何协作来解决上述所说的两个问题。

&emsp;&emsp;我们首先回答第一个问题，也就是主备NameNode是如何接替的，不知大家是否注意到，每个NameNode节点所在主机上都存在着一个DFSZKFailoverController节点（以下简称ZKFC），其实，ZKFC节点相当于ZooKeeper集群和 HDFS 集群交互的桥梁。主备交替由其和ZooKeeper集群（也就是QuorumPeerMain节点）共同完成。接下来让我们来看ZKFC节点的内部构成：

&emsp;&emsp;ZKFC内部存在 `HealthMonitor` 、`ActiveStandbyElector`和`FailoverController` 这三个主要组件。它们各自的作用如下：
* `HealthMonitor`主要负责检测 NameNode 的健康状态，并将状态变换通知``ZKFailoverController``。
* `ZKFailoverController`控制着NameNode状态切换的开关，一旦检测到NameNode状态变换，便告知`ActiveStandbyElector`需要选举。
* `ActiveStandbyElector`主要负责与ZooKeeper集群交互，需要选举时告知ZooKeeper集群，并接受选举结果并通知``ZKFailoverController``。
 
&emsp;&emsp;如图2-7所示，切换的流程大致可描述如下：
1. `HealthMonitor`对 NameNode 的健康状态进行检测，当检测到 NameNode的健康状态发生变化（即宕机），会通知`ZKFailoverController`。
2. `ZKFailoverController`判断需要进行主备切换，使用 `ActiveStandbyElector` 来与 Zookeeper集群进行交互完成自动的主备选举。
3. `ActiveStandbyElector`在主备选举完成后，会通知`ZKFailoverController`当前的 NameNode 成为主 NameNode 或备 NameNode。
4. `ZKFailoverController`将 NameNode 转换为 Active 状态或 Standby 状态。 

<p align="center">
    <img src="pic/2/2-7 NameNode的主备切换流程.jpg" width="50%">
    <br/>
    <em>图2-7 NameNode的主备切换流程 </em>
</p>


&emsp;&emsp;对于第二个问题，是由共享存储系统实现的，共享存储系统保存了NameNode在运行过程中所产生的HDFS的元数据。Active NameNode和Standby NameNode通过共享存储系统实现元数据同步。在进行主备切换的时候，新的Active NameNode在确认元数据完全同步之后才能继续对外提供服务，NameNode 的共享存储方案叫做QJM（Quorum Journal Manager），QJM便是利用新增的`JournalNode`节点实现的。接下来让我们简要描述 QJM 的共享存储方案的内部实现原理。

&emsp;&emsp;我们在2.2.3节中提到，Edits的作用是防止突然宕机，磁盘中的fsimage内容未正常更新，导致下次重新启动时读取到磁盘中过时的fsimage文件，最终造成一致性问题。而在HA-HDFS中，Standby NameNode和Active NameNode间也需要保证数据一致性，没有人想当NameNode切换后，整个目录结构即元数据与原来不同了。元数据的存储依赖于fsimage和Edits，只要将二者“同步”，也就实现了不同NameNode节点的同步。

&emsp;&emsp;QJM 的共享存储系统的数据同步机制简单来说便是——同步Edits。Active NameNode 每次将操作写入Edits时，首先需要把对应Edits提交到 JournalNode 集群，Standby NameNode 会定时从 JournalNode 集群中同步 Edits。如图2-8。这样就保持了Edits的一致性，可是光有Edits便足够了吗？不还需要同步fsimage吗？我们仔细思考，在2.2节中介绍过，最新的fsimage是由一个“过时”的fsimage叠加合并Edits得到的，而Edits已经做到了同步，也就是说，我们只需在某一时刻同步一次多个NameNode节点的fsimage，后续这些fsimage文件会合并由JournalNode 集群维护的相同的Edits，那么这多个fsimage自然也就是相同的了。这一同步fsimage的过程发生在我们最初配置HA-HDFS时：

>
>&emsp;&emsp;声明此机器为NameNode备机。
>
>&emsp;&emsp;`hdfs namenode > -bootstrapStandby`
>
>&emsp;&emsp;启动NameNode备机。
>
>&emsp;&emsp;`hdfs --daemon start namenode`

&emsp;&emsp;在这里便会将`m1`上的fsimage文件拷贝到`m2`中。


<p align="center">
    <img src="pic/2/2-8 QJM的数据同步机制.jpg" width="50%">
    <br/>
    <em>图2-8 QJM的数据同步机制 </em>
</p>

&emsp;&emsp;因为当前Active NameNode 发生了异常退出，Standby NameNode 需要转换为Active时，Standby NameNode的Edits是定时同步的，故很有可能落后于最新的Edits，所以首先要做的事情就是让 JournalNode 集群中各个节点上的 Edits 恢复为一致，补齐落后的操作。完成该步骤后，当前新的Active NameNode便能安全地对外提供服务。