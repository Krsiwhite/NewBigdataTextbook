## 2.2 HDFS：仓库管理员
&emsp;&emsp;HDFS是一个标准的主从（Master/Slave）体系结构的分布式系统，被设计成适合在通用硬件上运行；HDFS集群包含一个主机(NameNode)和多个从机(DataNode)，它们各司其职提供服务，用户可以通过多种方式同 NameNode 进行交互以访问文件系统。HDFS采用Java语言开发，因此任何支持Java的机器都可以部署 HDFS。

&emsp;&emsp;在逻辑设计上，其采用传统的层次型文件组织结构。用户或者应用程序可以创建目录，然后将文件保存在这些目录里。文件系统名字空间的层次结构和大多数现有的文件系统类似：用户可以创建、删除、移动或重命名文件。这样的目录结构由 NameNode 进行管理和维护，同时 NameNode 还负责与用户交互，进行文件的读写操作。而具体的数据以数据块（Block）的形式存储在 DataNode 上，DataNode是 HDFS 集群中真正存储数据的节点。举例来说，当用户要向HDFS中写入一个文件时，会与 NameNode 交互，NameNode会将数据划分为固定大小，对应数量的多个Block，这些Block最终会被分散存储到多个DataNode上，这就实现了分布式存储。一般来说，集群中所有的主机上都有DataNode，而只有一台主机上运行着NameNode。

&emsp;&emsp;HDFS 运行在多台主机上，如何决定数据该存储在哪台主机？在这其中， NameNode 和 DataNode 的作用各是什么？让我们首先部署一个 HDFS 集群，再带着问题一起学习。

### 2.2.1 部署 HDFS 集群
&emsp;&emsp;HDFS 是 Hadoop 生态的一部分，而 Hadoop 又是构建在 Java（严格说是Java8） 之上，所以准备好你的三台Linux主机，我们要开始部署 HDFS 集群啦！部署的过程应该是：  


1. 配置三台主机ssh免密登录
2. 安装Java8
3. 安装Hadoop
4. 配置HDFS集群参数
5. 同步HDFS集群参数
6. 启动HDFS集群

&emsp;&emsp;首先，应该确保在实验过程中各个端口能被正常使用，如果使用运营商提供的服务器，建议在防火墙规则上对所有端口放行，如是华为云服务器，则防火墙规则选择`System-FullAccess`。

&emsp;&emsp;为了方便后续实验，我们需要在配置hosts文件，将我们的三台主机的ip地址映射为机器号。在每台主机上编辑`/etc/hosts`。在文件末尾追加：
```
192.168.0.2 m1  #ip地址根据你的主机情况填写
192.168.0.3 m2
192.168.0.4 m3
```
&emsp;&emsp;在本书的环境中，三台主机处于同一个局域网下，故使用私有IP地址，读者需根据自身主机/虚拟机实际ip地址设置映射关系。在下文中`m1,m2,m3`均指代如上的三台主机。

**（1）配置免密登录**

&emsp;&emsp;在 HDFS 集群中，我们可以在一台主机上发送命令来启动整个集群，这意味着一台主机需要拥有操纵其他主机的权限，这就需要我们配置免密登录，使得集群中主机间能够相互访问。

&emsp;&emsp;在主机上执行`ssh-keygen`来生成密钥，此时会要求为密钥输入密码，由于需要是免密登录的密钥，在这连按两次回车跳过即可。执行完后会在`.ssh/`目录下生成两个密钥文件`id_xxxx`和`id_xxxx.pub`，分别是私钥和公钥，将公钥存储在另一台主机中，另一台主机便可免密登录该主机。故接下来执行：
```
ssh-copy-id m1
ssh-copy-id m2
ssh-copy-id m3
 ```

将该主机公钥存储在所有主机上，这里需要输入各台主机的登录密码。在集群中所有主机中都要执行如上所示的`ssh-keygen`和`ssh-copy-id`指令。

**（2）安装Java8**

_Java的安装在三台主机上都要执行_


&emsp;&emsp;首先更新软件包索引，否则可能导致后续安装失败。

&emsp;&emsp;`sudo apt-get update`

&emsp;&emsp;接着，安装JDK，指定版本Java8。

&emsp;&emsp;` apt install openjdk-8-jdk-headless`



&emsp;&emsp;然后为Java配置环境变量。编辑`/etc/profile`文件，在文件末尾追加：

```
export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64
export PATH=$PATH:$JAVA_HOME/bin
```

&emsp;&emsp;注意`JAVA_HOME`应指向Java安装目录，输入指令`whereis java`可查看。最后`source /etc/profile`更新环境变量。


&emsp;&emsp;输入指令验证是否安装成功。
```
root@m1:~# java -version
openjdk version "1.8.0_452"
OpenJDK Runtime Environment (build 1.8.0_452-8u452-ga~us1-0ubuntu1~24.04-b09)
OpenJDK 64-Bit Server VM (build 25.452-b09, mixed mode)
```

**（3）安装 Hadoop**

_只在一台主机上执行_

&emsp;&emsp;本书实验采用3.3.6版本。后续的下载、安装目录均在管理员的家目录`/root`。首先从国内清华镜像源下载，若从官网下载则速度较慢。

&emsp;&emsp;`wget https://mirrors.tuna.tsinghua.edu.cn/apache/hadoop/common/hadoop
3.3.6/hadoop-3.3.6.tar.gz`

&emsp;&emsp;接着解压。

&emsp;&emsp;`tar -zxvf hadoop-3.3.6.tar.gz `

&emsp;&emsp;配置环境变量。依旧修改`/etc/profile`文件，将（2）中所添加部分修改如下：

```
export HADOOP_HOME=/root/hadoop-3.3.6
export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64
export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin:$JAVA_HOME/bin
```
&emsp;&emsp;同样的，`source /etc/profile`更新环境变量。输入指令验证Hadoop安装成功。

```
root@m1:~# hadoop version
Hadoop 3.3.6
Source code repository https://github.com/apache/hadoop.git -r 1be78238728da9266a4f88195058f08fd012bf9c
Compiled by ubuntu on 2023-06-18T08:22Z
Compiled on platform linux-x86_64
Compiled with protoc 3.7.1
From source with checksum 5652179ad55f76cb287d9c633bb53bbd
This command was run using /root/hadoop-3.3.6/share/hadoop/common/hadoop-common-3.3.6.jar
```

**（4）配置 HDFS 集群参数**

_只在一台主机上执行_

&emsp;&emsp;接下来需要编辑HADOOP的一些配置文件。在`hadoop-3.3.6/etc/hadoop/`目录下，存在许多各种组件的配置文件：
```
hadoop-3.3.6
    |--etc
        |--hadoop
            |--core-site.xml   #Hadoop的核心配置文件
            |--hdfs-site.xml   #HDFS的核心配置文件
            |--mapred-site.xml #MapReduce的核心配置文件
            |--......
```

&emsp;&emsp;在这里我们主要配置 HDFS 集群，但顺带会部署一些其他组件以方便后续使用。首先编辑`core-site.xml`。将其修改为：

```
<configuration>
    <property>
        <!-- HDFS的主机和端口号，这里设置在m1上 -->
        <name>fs.defaultFS</name>        
        <value>hdfs://m1:9000</value>
    </property>  
    <property>
        <!-- Hadoop产生数据存储目录 -->
        <name>hadoop.tmp.dir</name>
        <value>/root/hadoop/data</value>
    </property>
 </configuration>
```

&emsp;&emsp;其次是`hdfs-site.xml`。

```
<configuration>
    <property>
        <!-- namenode数据存储目录，若未指定，则在hadoop.tmp.dir下 -->
        <name>dfs.name.dir</name>
        <value>/root/hdfs/namenode</value>
    </property>
    <property>
        <!-- 同上 -->
        <name>dfs.data.dir</name>
        <value>/root/hdfs/datanode</value>
    </property>
    <property>
        <!-- 数据在hdfs中的备份次数 -->
        <name>dfs.replication</name>
        <value>3</value>
    </property>
</configuration>
```

&emsp;&emsp;接着编辑同目录下的`hadoop-env.sh`，根据你的Java目录，在文末追加：`export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64`

&emsp;&emsp;如果使用的是管理员账号，还需额外添加：

```
export HDFS_NAMENODE_USER="root"       
export HDFS_DATANODE_USER="root"       
```

&emsp;&emsp;最后，编辑同目录下的`workers`，其为一空文件，该文件作用为指定集群中应包含哪些主机。应将其指定为最初在`/etc/hosts`中映射的三台主机，每台主机单独一行，在书中为：
```
m1
m2
m3
```

**（5）同步HDFS集群参数**

&emsp;&emsp;由于第（3）、（4）步中我们只在一台主机上安装了HADOOP，故需将配置好的HADOOP以及修改过的`/etc/profile`发送给其余所有主机，并激活配置文件。使用命令：
```
scp -r /root/hadoop-3.3.6 m2:/root
scp -r /root/hadoop-3.3.6 m3:/root
scp -r /etc/profile m2:/etc
scp -r /etc/profile m3:/etc
 ```
之后在所有主机上：
```
source $HADOOP_HOME/etc/hadoop/hadoop-env.sh
source /etc/profile
```

**（6）启动HDFS集群**

&emsp;&emsp;在m1上执行NameNode初始化，这一步类似于常说的格式化，生成一个初始的文件系统：`hadoop namenode -format`，紧接着就可以启动了，在`m1`上，执行`start-dfs.sh`，含义为单独启动 HDFS 集群。
```
root@m1:~# start-dfs.sh 
Starting namenodes on m1
Starting datanodes
```
在各台主机上使用命令`jps`，可查看运行的节点信息。此时，在`m1`上应为：
```
root@m1:~# jps
2658 NameNode
2810 DataNode
6894 Jps
```
可看到此时`m1`上运行着一个NameNode节点和一个DataNode节点，节点前的数字为该节点所对应的进程号。在`m2`和`m3`上执行指令结果应如下：
```
root@m2:~# jps
6588 Jps
2703 DataNode
```
&emsp;&emsp;到这里，我们的 HDFS 集群就算成功启动了。让我们实验一下吧！在`m1`即NameNode节点所在主机上输入命令：`hdfs dfs -mkdir /hello_world`创建文件夹，然后再输入`hdfs dfs -ls /`查看根目录下所有文件。
```
root@m1:~# hdfs dfs -mkdir /hello_world
root@m1:~# hdfs dfs -ls /
Found 1 items
drwxr-xr-x   - root supergroup          0 2025-05-15 15:20 /hello_world
```
可以看到我们刚刚所创建的文件夹。

### 2.2.2 通过 Web 访问 HDFS 集群














