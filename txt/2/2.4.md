### 2.4.2 部署HBase集群

&emsp;&emsp;HBase作为Hadoop生态中的分布式数据库，构建在HDFS和ZooKeeper之上，如同一位精密的钟表师，需要协调多个组件才能完美运转。准备好您的Linux主机（建议至少三台），让我们开始部署HBase集群吧！部署过程应该是：

1. 安装HBase 
2. 配置HBase集群参数 
3. 同步HBase集群参数 
4. 启动HBase集群参数
5. 验证高可用

**（1）安装HBase**

只在一台主机上执行（在这里，选择在`m3`上执行）

&emsp;&emsp;本书实验采用2.5.11版本。后续的下载、安装目录均在管理员的家目录`/root`。首先从官网下载。

&emsp;&emsp;`wget https://mirrors.tuna.tsinghua.edu.cn/apache/hbase/2.5.11/hbase-2.5.11-bin.tar.gz`

&emsp;&emsp;接着解压。

&emsp;&emsp;`tar -xzvf hbase-2.5.11-bin.tar.gz`

&emsp;&emsp;配置环境变量。修改`/etc/profile`文件，通过`vim`进入`/etc/profile`文件：

```
vim /etc/profile
```

&emsp;&emsp;将`/etc/profile`文件的内容修改为：

```
export HADOOP_HOME=/root/hadoop-3.3.6
export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64
export HBASE_HOME=/root/hbase-2.5.11
export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin:$JAVA_HOME/bin:$HBASE_HOME/bin
```

&emsp;&emsp;同样的，`source /etc/profile`更新环境变量。输入指令验证HBase安装成功。

```
root@m1:~# hbase version
HBase 2.5.11
...
```

**（2）配置HBase集群参数** 

只在一台主机上执行（在这里，选择在`m3`上执行）

&emsp;&emsp;接下来需要编辑HBase的一些配置文件。在`hbase-2.5.11/conf`目录下，存在许多各种组件的配置文件：

```
hbase-2.5.11
    |--conf
        |--hbase-site.xml   #HBase的核心配置文件
        |--hbase-env.sh     #HBase的核心配置文件
        |--regionservers    #HBase的核心配置文件
        |--backup-masters   #HBase的核心配置文件
        |--......
```

&emsp;&emsp;在这里，我们主要配置HBase集群。首先进入hbase下的`conf`文件夹：

```
root@m3:~# cd hbase-2.5.11/conf/
```

&emsp;&emsp;编辑`hbase-site.xml`，通过`vim hbase-site.xml`修改`hbase-site.xml`文件，将其修改为：

```
<configuration>
    <property>
          <!--指定Zookeeper集群节点-->
          <name>hbase.zookeeper.quorum</name>
          <value>m1,m2,m3</value>
    </property>

    <property>
          <!--指定Zookeeper端口号-->
          <name>hbase.zookeeper.property.clientPort</name>
          <value>2181</value>
    </property>
    <property>
          <!--指定HBase在HDFS上的根目录-->
          <name>hbase.rootdir</name>
          <value>hdfs://hdfs-cluster/hbase</value>
    </property>
    <property>
          <!--指定true为分布式集群部署-->
          <name>hbase.cluster.distributed</name>
          <value>true</value>
     </property>
     <!-- 开启配置防止 hmaster 启动问题 -->
  <property>
    <name>hbase.unsafe.stream.capability.enforce</name>
    <value>false</value>
  </property>

  <!-- 监控页面端口 -->
  <property>
    <name>hbase.master.info.port</name>
    <value>60010</value>
  </property>
      <property>
    <name>hbase.tmp.dir</name>
    <value>./tmp</value>
  </property>
<property>
    <name>hbase.wal.provider</name>
    <value>filesystem</value>
</property>

</configuration>
```

&emsp;&emsp;其次，通过`vim regionservers`进入`regionservers`文件，将其修改为：

```
m1
m2
m3
```

&emsp;&emsp;接着，编辑同目录下的`hbase-env.sh`，通过`vim hbase-env.sh`进入文件，添加相关环境变量，并且不使用内置的ZooKeeper集群，改为使用我们自己的ZooKeeper集群。

```
export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64
export HBASE_MANAGES_ZK=false
```

&emsp;&emsp;最后，将`/root/hadoop-3.3.6/etc/hadoop`中的`hdfs-site.xml`文件和`core-site.xml`文件复制进入`/root/hbase-2.5.11/conf`中。

```
cp /root/hadoop-3.3.6/etc/hadoop/hdfs-site.xml /root/hbase-2.5.11/conf
cp /root/hadoop-3.3.6/etc/hadoop/core-site.xml /root/hbase-2.5.11/conf
```

**（3）同步HBase集群参数** 

&emsp;&emsp;由于第（1）、（2）步中我们只在一台主机上安装了HBase，故需将配置好的HBase以及修改过的`/etc/profile`发送给其余所有主机，并激活配置文件。使用命令：

```
scp -r /root/hbase-2.5.11 m1:/root
scp -r /root/hbase-2.5.11 m2:/root
scp -r /etc/profile m1:/etc
scp -r /etc/profile m2:/etc
```

&emsp;&emsp;之后，在所有的主机上：

```
source hbase-env.sh
source /etc/profile
```

**（4）启动HBase集群**

&emsp;&emsp;启动ZooKeeper集群，在集群所有节点（m1，m2，m3）上分别执行以下命令启动ZooKeeper集群

```
root@m1:~# zookeeper-3.8.4/bin/zkServer.sh start
ZooKeeper JMX enabled by default
Using config: /root/zookeeper-3.8.4/bin/../conf/zoo.cfg
Starting zookeeper ... STARTED
root@m2:~# zookeeper-3.8.4/bin/zkServer.sh start
ZooKeeper JMX enabled by default
Using config: /root/zookeeper-3.8.4/bin/../conf/zoo.cfg
Starting zookeeper ... STARTED
root@m3:~# zookeeper-3.8.4/bin/zkServer.sh start
ZooKeeper JMX enabled by default
Using config: /root/zookeeper-3.8.4/bin/../conf/zoo.cfg
Starting zookeeper ... STARTED
```

&emsp;&emsp;启动HDFS集群，在一台主机上执行以下命令启动HDFS集群（在这里，我们在`m1`上启动HBase集群）

```
root@m3:~# start-dfs.sh 
Starting namenodes on m3
Starting datanodes
```

&emsp;&emsp;启动HBase集群，在一台主机上执行以下命令启动HBase集群，在哪台节点上执行`start-hbase.sh`，哪个节点就是主节点（在这里，我们在`m3`上启动HBase集群）

```
root@m3:~# start-hbase.sh
running master, logging to /root/hbase-2.5.11/logs/hbase-root-master-m3.out
```

&emsp;&emsp;在备选节点`m2`上再启动一个 HMaster 主进程

```
root@m2:~# hbase-daemon.sh start master
```

&emsp;&emsp;在各台主机上使用命令`jps`，可查看运行的节点信息。此时，在`m2`和`m3`上应为：

```
root@m3:~# jps
5396 HRegionServer
2357 DataNode
5718 Jps
2153 NameNode
1802 QuorumPeerMain
4639 HMaster
root@m2:~# jps
1760 NodeManager
6273 HRegionServer
11826 Jps
5867 QuorumPeerMain
37868 HMaster
1581 DataNode
```

&emsp;&emsp;可看到此时`m2`和`m3`上运行着一个HMaster和HRegionServer两个进程，节点前的数字为该节点所对应的进程号。在`m3`上，HMaster为集群管理进程，负责元数据操作、Region分配和故障转移，而HRegionServer为数据服务进程，处理客户端读写请求，管理Region数据。在`m2`上，HMaster为备选集群管理进程，负责在主HMaster崩溃时，通过ZooKeeper选举立即接管成为新主节点，避免服务中断，而HRegionServer为纯数据节点，只负责存储和处理分配给它的Region数据。

&emsp;&emsp;在`m1`上应为：

```
root@m1:~# jps
1927 NodeManager
6153 QuorumPeerMain
6635 HRegionServer
1581 DataNode
1758 SecondaryNameNode
12719 Jps
```

&emsp;&emsp;此时，`m1`会出现HRegionServer这个进程。在`m1`和`m2`中，HRegionServer为纯数据节点，只负责存储和处理分配给它的Region数据。

（5） 验证高可用

&emsp;&emsp;HBase可以通过Web可视化的方式访问，Web网页端访问端口配置在`hbase-site.xml`文件中的`hbase.master.info.port`节点上，在这里，将端口设置为`60010`：

```
<property>
<name>hbase.master.info.port</name>
<value>60010</value>
</property>
```

&emsp;&emsp;在浏览器打开HBase主节点网页端，如图2-12所示。我们可以在主界面看到一些基本的内容：

1. Region Servers状态表：Region Servers状态表显示当前集群中所有RegionServer的运行状态，包括ServerName、启动时间、HBase版本等信息；
2. 备选节点状态表：备选节点状态表显示当前集群中备选节点（Backup Masters）的主要信息，包括主机名、端口以及启动时间；

3. Tables概览：Tables汇总了所有表的分类和状态，用户表（User Tables）和 系统表（System Tables，如 `hbase:meta`）、快照以及命名空间下的表状态。

<p align="center">
    <img src="/pic/2/2-12 HBase主节点网页端.png" width="50%">
    <br/>
    <em>图2-12 HBase主节点网页端</em>
</p>


&emsp;&emsp;在浏览器打开HBase备选节点网页端，如图2-13所示。我们可以在主界面看到一些基本的内容：

1. 核心节点状态：核心节点状态显示当前活跃的Master为`m3`；
2. 任务管理表格：任务管理表格包含功能选项卡以及任务记录。

<p align="center">
    <img src="/pic/2/2-13 HBase备选节点网页端.png" width="50%">
    <br/>
    <em>图2-13 HBase备选节点网页端</em>
</p>


&emsp;&emsp;想要验证HBase的高可用性，首先需要干掉`m3`上的HMaster进程，观察备选节点`m2`启用。

```
root@m3:~# jps
5236 QuorumPeerMain
40852 Jps
9892 JournalNode
9733 DataNode
13319 HMaster
13543 HRegionServer
root@m3:~# kill -9 13319
```

&emsp;&emsp;干掉`m3`上的HMaster进程后，发现界面无法访问，如图2-14所示。

<p align="center">
    <img src="/pic/2/2-14 主节点m3干掉HMaster进程后的网页端.png" width="50%">
    <br/>
    <em>图2-14 主节点m3干掉HMaster进程后的网页端</em>
</p>

&emsp;&emsp;并发现备选节点`m2`变成了主节点，可以发现`m2`节点的网页端已经变成了主节点网页端！如图2-15所示。

<p align="center">
    <img src="/pic/2/2-15 备选节点m2变成主节点网页端.png" width="50%">
    <br/>
    <em>图2-15 备选节点m2变成主节点网页端</em>
</p>


### 2.4.3 HBase基础操作实践

**（1）操作环境**

&emsp;&emsp;服务器规格： Ubuntu 24.04 server 64bit 节点数⽬：3

&emsp;&emsp;Hadoop 版本： Apache Hadoop 3.3.6

&emsp;&emsp;zookeeper 版本： 3.8.4

&emsp;&emsp;HBase 版本： 2.5.11

**（2）操作步骤**

**1.启动 Hadoop、HBase 及 zookeeper：**

&emsp;&emsp;在 **所有节点** 都运⾏ `zkServer.sh start` 以启动 zookeeper;

&emsp;&emsp;在 **节点 m1**运⾏ `start-all.sh` 以启动 Hadoop集群;

&emsp;&emsp;启动后⽤ `zkServer.sh status` 和 `jps` 命令检查各个服务是否正常启动;

**2.使⽤ HBase Shell连接 HBase：**

&emsp;&emsp;在 **节点 m1**运⾏ `start-hbase.sh` 启动 HBase 服务；

&emsp;&emsp;运⾏ `hbase shell` 进⼊ hbase shell, 接下来关于 hbase的数据操作命令都是在 hbase shell中执⾏。

**3.HBase 操作：**

&emsp;&emsp;创建表 student，设置 2个列簇，分别为 stuinfo 和 course，并显示表结构:

```shell
# 创建表 
create 'student',{NAME=>'stuinfo'},{NAME=>'course'}

#查看表结构
describe 'student' 
```

&emsp;&emsp;可以在HBase浏览器端查看表结构：


&emsp;&emsp;修改表结构，course 列簇返回最⼤版本数为 3，并显示表结构：
<p align="center">
    <img src="/pic/2/2-17 浏览器端查看.png" width="50%">
    <br/>
    <em>图2-17 浏览器端查看</em>
</p>

```shell
# 修改表结构
alter 'student',{NAME=>'course',VERSIONS=>3} 

describe 'student'
```

&emsp;&emsp;向列簇中增加列：

```shell
stuinfo 列簇: name,age,sex,dept 
course 列簇: english,math,physics
```
&emsp;&emsp;由于 HBase是采⽤动态添加列，在插⼊数据的同时插⼊列，因此这一步统⼀放在下一步完成。

&emsp;&emsp;向表中添加数据，添加四条学⽣信息:

```shell
put 'student','1','stuinfo:name','laowang' 
put 'student','1','stuinfo:age','18'
put 'student','1','stuinfo:sex','male'
put 'student','1','stuinfo:dept','CS'
put 'student','1','course:english','100' 
put 'student','1','course:math','90'
put 'student','1','course:physics','80'
put 'student','2','stuinfo:name','chris' 
put 'student','2','stuinfo:age','36'
put 'student','2','stuinfo:sex','male' 
put 'student','2','stuinfo:dept','CS' 
put 'student','2','course:english','90' 
put 'student','2','course:math','80'
put 'student','2','course:physics','100'
```

&emsp;&emsp;Note: 由于命令过多且格式相同，故只列出部分命令，都按照 `put 表名, ⾏号, 列簇: 列名, 数据`
的格式插⼊数据。
<p align="center">
    <img src="/pic/2/2-4 学生表.png" width="50%">
    <br/>
    <em>图2-4 学生信息表</em>
</p>

&emsp;&emsp;添加完数据后，⽤ scan 命令查询 student 表中的所有信息：

```shell
# 查询表信息
scan 'student' 
```

&emsp;&emsp;添加完数据后，查询 student 表中指定列簇或列簇中某个列的所有信息：

```shell
# 查询 stuinfo 列簇中的所有信息 
scan 'student', {COLUMN=>'stuinfo'} 

# 查询 stuinfo:sex 列中的所有信息
scan 'student', {COLUMN=>'stuinfo:sex'} 

# 通过 LIMIT 限定查询到的⾏数
scan 'student', {LIMIT=>2, COLUMN=>'stuinfo'} 
```

&emsp;&emsp;更新数据，将 course 列簇中的 english 列的值减 5：

```shell
put 'student','1','course:english','95'
```

&emsp;&emsp;Note：HBase ⽆法统⼀修改数据，只能⼀个个数据重新赋值。

&emsp;&emsp;使⽤ get 查询指定⾏对应列簇或列的信息：

```shell
# 查询第 "1" ⾏ course列簇的信息
get 'student', '1', 'course' 

# 查询第 "1"⾏ course列簇中 english列的信息
get 'student', '1', 'course:english'  

# 查询第 "1"⾏中所有信息
get 'student, '1' 
```

&emsp;&emsp;删除 student 表：

```shell
# 先使表失效，才能删除
disable 'student' 

# 删除表p
drop 'student'
```
### 2.4.4 HBase 原理
1. HBase 数据模型

&emsp;&emsp;HBase 的数据模型是理解其核心原理的关键部分，本节主要介绍HBase数据模型。与传统的关系型数据库不同，HBase 并不像传统的关系型数据库MySQL，以“行和列”的二维结构进行固定模式的存储，而是采用一种灵活的、稀疏的、面向列族（Column Family）的数据模型。

&emsp;&emsp;如何理解HBase的列式存储呢？下图中有两名学生的成绩，这种熟悉的数据组织方式正是MySQL的存储方式——行式存储。那么如何按照“列”将其存储于HBase中呢？
<p align="center">
    <img src="/pic/2/2-17 学生成绩表.png" width="50%">
    <br/>
    <em>图2-17 学生成绩表</em>
</p>

&emsp;&emsp;HBase 中的数据以“表（Table）”的形式组织，每行由唯一的“行键（Row Key）”标识，行内数据再划分为多个“列族（Column Family）”，每个列族包含若干个“列限定符（Qualifier）”。此外，每条数据都有对应的“时间戳（Timestamp）”，用于版本控制。可以理解为HBase本质上是一个结构化的、支持多版本的 Key-Value 存储系统。其中，完整的 Key 结构是：RowKey + Column Family + Qualifier + Timestamp。每一条数据的定位，依赖这个四元组，而 Value 就是对应的值。

&emsp;&emsp;上面这段话对于初学者来说理解起来可能有点难度，不妨画个图理解一下：
<p align="center">
    <img src="/pic/2/2-18 列式存储.png" width="50%">
    <br/>
    <em>图2-18 列式存储</em>
</p>

&emsp;&emsp;可能还是难以理解，让我们放点具体的值看一下：
<p align="center">
    <img src="/pic/2/2-19 列式存储-具体值.png" width="50%">
    <br/>
    <em>图2-19 列式存储-具体值</em>
</p>
&emsp;&emsp;这张表我们有两个列族，分别是 StudentInfo 和 ScoreInfo。在 StudentInfo 下有两个列，分别是 StudentInfo:name 和StudentInfo:stu_id，在 ScoreInfo 下有两个列，分别是 ScoreInfo:Chinese 和 ScoreInfo:math。其中，对于主键（RowKey）为 1 的数据：其 StudentInfo:name 的值为：张三。StudentInfo:stu_id 的值为222。ScoreInfo:Chinese的值为90。ScoreInfo:math的值为100。

&emsp;&emsp;HBase表的每一行中，列的组成都是灵活的，行与行之间的列不需要相同.换句话说：一个列族下可以任意添加列，不受任何限制。

2. HBase 数据写入流程

&emsp;&emsp;当用户或应用向 HBase 写入一条数据时，完整流程如下：

&emsp;&emsp;客户端发起写请求：客户端通过 RowKey 定位到对应的 Region，Zookeeper 会返回哪个 RegionServer 管理该 Region。

&emsp;&emsp;写入 WAL（Write-Ahead Log）：为防止服务器故障导致数据丢失，写入操作首先记录在预写日志中，即使系统宕机也可通过日志恢复数据。

&emsp;&emsp;写入 MemStore（内存缓存）：接下来，数据会写入内存结构 MemStore，提升写入速度。

&emsp;&emsp;Flush：：当 MemStore 达到一定阈值（比如 128MB），系统会触发 flush，将内存数据持久化为 HFile 文件，存储到 HDFS。

&emsp;&emsp;合并（Compaction）：多个小文件会被后台合并成更大的文件，减少查询时磁盘 IO。分为 Minor 和 Major 两种 compaction。

3. HBase 数据读取流程

&emsp;&emsp;HBase 的读取是“多层次缓存+磁盘”的组合模式，流程如下：

&emsp;&emsp;客户端发起读请求：客户端通过 RowKey 访问数据，Zookeeper 返回对应的 RegionServer。

&emsp;&emsp;检查 MemStore（内存）：首先在 MemStore 中查找，看是否有最新还未落盘的数据。

&emsp;&emsp;查询 BlockCache（读缓存）：如果 MemStore 未命中，则访问 BlockCache，这是 HBase 的读缓存，可以极大减少磁盘访问次数。

&emsp;&emsp;读取 HFile（磁盘）：缓存未命中时，再读取底层的 HFile。为了加快速度，HFile 设计了索引和布隆过滤器，避免全量扫描。

&emsp;&emsp;返回数据到客户端：最终将结果返回客户端，同时更新缓存（BlockCache）以加速下一次查询。