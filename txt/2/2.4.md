### 2.4.1 部署HBase集群

HBase作为Hadoop生态中的分布式数据库，构建在HDFS和ZooKeeper之上，如同一位精密的钟表师，需要协调多个组件才能完美运转。准备好您的Linux主机（建议至少三台），让我们开始部署HBase集群吧！部署过程应该是：

1. 安装HBase 
2. 配置HBase集群参数 
3. 同步HBase集群参数 
4. 启动HBase集群参数

**（1）安装HBase**

只在一台主机上执行

​	本书实验采用2.5.11版本。后续的下载、安装目录均在管理员的家目录`/root`。首先从官网下载。

​	`wget https://mirrors.tuna.tsinghua.edu.cn/apache/hbase/2.5.11/hbase-2.5.11-bin.tar.gz`

​	接着解压。

​	`tar -xzvf hbase-2.5.11-bin.tar.gz`

​	配置环境变量。修改`/etc/profile`文件，将`/etc/profile`文件的内容修改为：

```
export HADOOP_HOME=/root/hadoop-3.3.6
export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64
export HBASE_HOME=/root/hbase-2.5.11
export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin:$JAVA_HOME/bin:$HBASE_HOME/bin
```

​	同样的，`source /etc/profile`更新环境变量。输入指令验证HBase安装成功。

```
root@m1:~# hbase version
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/root/hbase-2.5.11/lib/client-facing-thirdparty/log4j-slf4j-impl-2.17.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/root/hadoop-3.3.6/share/hadoop/common/lib/slf4j-reload4j-1.7.36.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]
HBase 2.5.11
Source code repository git://buildbox.localdomain/home/apurtell/tmp/RM/hbase revision=505b485e462c9cbd318116155b3e37204469085a
Compiled by apurtell on Mon Feb 17 16:48:36 PST 2025
From source with checksum 6332bbda9ee95c46b73d497bdc8a045a611f5f5e97439d4a786fe1df08b2d9748a33f8dce5bcf509cac15bcae1d6bc8de0e40fe890d9c477a165f9aa68df1294
```

**（2）配置HBase集群参数** 

只在一台主机上执行

​	接下来需要编辑HBase的一些配置文件。在`hbase-2.5.11/conf`目录下，存在许多各种组件的配置文件：

```
hbase-2.5.11
    |--conf
        |--hbase-site.xml   #HBase的核心配置文件
        |--hbase-env.sh     #HBase的核心配置文件
        |--regionservers    #HBase的核心配置文件
        |--backup-masters   #HBase的核心配置文件
        |--......
```

​	在这里，我们主要配置HBase集群。首先编辑`hbase-site.xml`，将其修改为：

```
<configuration>
    <property>
          <!--指定Zookeeper集群节点-->
          <name>hbase.zookeeper.quorum</name>
          <value>m1,m2,m3</value>
    </property>
    <property>
          <!--指定Zookeeper数据存储目录-->
          <name>hbase.zookeeper.property.dataDir</name>
          <value>/root/zookeeper-3.5.7/zkData</value>
    </property>
    <property>
          <!--指定Zookeeper端口号-->
          <name>hbase.zookeeper.property.clientPort</name>
          <value>2181</value>
    </property>
    <property>
          <!--指定HBase在HDFS上的根目录-->
          <name>hbase.rootdir</name>
          <value>file:///root/hbase-2.5.11/hbase-tmp</value>
    </property>
    <property>
     	  <!--指定true为分布式集群部署-->
          <name>hbase.cluster.distributed</name>
          <value>true</value>
     </property>
</configuration>
```

​	其次是`regionservers`。

```
localhost
m1
m2
m3
```

​	接着，编辑同目录下的`backup-masters`，如若目录下没有该文件，则新增`backup-masters`配置文件，为HMaster角色配置高可用，这里选择m1作为备用节点。

```
m1
```

​	最后，编辑同目录下的`hbase-env.sh`，添加相关环境变量，并且不使用内置的ZooKeeper集群，改为使用我们自己的ZooKeeper集群。

```
export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64
export HBASE_MANAGES_ZK=false
```

**（3）同步HBase集群参数** 

​	由于第（1）、（2）步中我们只在一台主机上安装了HBase，故需将配置好的HBase以及修改过的`/etc/profile`发送给其余所有主机，并激活配置文件。使用命令：

```
scp -r /root/hbase-2.5.11 m2:/root
scp -r /root/hbase-2.5.11 m3:/root
scp -r /etc/profile m2:/etc
scp -r /etc/profile m3:/etc
```

​	发送之后，为HMaster角色配置高可用，这里需要修改`backup-masters`，分别在另外两台主机上分别修改：

​	第二台主机中的`backup-masters`：	

```
m2
```

​	第三台主机中的`backup-masters`：

```
m3
```

​	之后，在所有的主机上：

```
source hbase-env.sh
source /etc/profile
```

**（4）启动HBase集群**

​	启动ZooKeeper集群，在集群所有节点（m1，m2，m3）上分别执行以下命令启动ZooKeeper集群

```
root@m1:~# zookeeper-3.5.7/bin/zkServer.sh start
ZooKeeper JMX enabled by default
Using config: /root/zookeeper-3.5.7/bin/../conf/zoo.cfg
Starting zookeeper ... STARTED
```

```
root@m2:~# zookeeper-3.5.7/bin/zkServer.sh start
ZooKeeper JMX enabled by default
Using config: /root/zookeeper-3.5.7/bin/../conf/zoo.cfg
Starting zookeeper ... STARTED
```

```
root@m3:~# zookeeper-3.5.7/bin/zkServer.sh start
ZooKeeper JMX enabled by default
Using config: /root/zookeeper-3.5.7/bin/../conf/zoo.cfg
Starting zookeeper ... STARTED
```

​	启动HDFS集群，在m1上执行以下命令启动HDFS集群

```
root@m1:~# start-dfs.sh 
Starting namenodes on m1
Starting datanodes
```

​	启动HBase集群，在m1上执行以下命令启动HBase集群

```
root@m1:~# start-hbase.sh
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/root/hbase-2.5.11/lib/client-facing-thirdparty/log4j-slf4j-impl-2.17.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/root/hadoop-3.3.6/share/hadoop/common/lib/slf4j-reload4j-1.7.36.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]
running master, logging to /root/hbase-2.5.11/logs/hbase-root-master-m1.out
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/root/hbase-2.5.11/lib/client-facing-thirdparty/log4j-slf4j-impl-2.17.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/root/hadoop-3.3.6/share/hadoop/common/lib/slf4j-reload4j-1.7.36.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]
```

​	在各台主机上使用命令`jps`，可查看运行的节点信息。此时，在`m1`上应为：

```
root@m1:~# jps
2336 ResourceManager
1956 DataNode
7991 QuorumPeerMain
9259 HRegionServer
17820 Jps
1757 NameNode
2541 NodeManager
```

​	可看到此时`m1`上运行着一个HMaster和HRegionServer两个进程，节点前的数字为该节点所对应的进程号。在`m1`上，HMaster为集群管理进程，负责元数据操作、Region分配和故障转移，而HRegionServer为数据服务进程，处理客户端读写请求，管理Region数据。

​	在`m2`和`m3`上执行命令应如下：

```
root@m2:~# jps
1927 NodeManager
6153 QuorumPeerMain
6635 HRegionServer
1581 DataNode
2110 JobHistoryServer
1758 SecondaryNameNode
12719 Jps
```

```
root@m3:~# jps
1760 NodeManager
6273 HRegionServer
11826 Jps
5867 QuorumPeerMain
1581 DataNode
```

​	此时，`m2`和`m3`会出现HRegionServer这个进程。在`m2`和`m3`中，HRegionServer为纯数据节点，只负责存储和处理分配给它的Region数据。

### 2.4.2 HBase基础操作实践

**（1）操作环境**

&emsp;&emsp;服务器规格： Ubuntu 24.04 server 64bit 节点数⽬：3

&emsp;&emsp;Hadoop 版本： Apache Hadoop 3.3.6

&emsp;&emsp;zookeeper 版本： 3.8.4

&emsp;&emsp;HBase 版本： 2.5.11

**（2）操作步骤**

**1.启动 Hadoop、HBase 及 zookeeper：**

&emsp;&emsp;在 **所有节点** 都运⾏ `zkServer.sh start` 以启动 zookeeper;

&emsp;&emsp;在 **节点 m1**运⾏ `start-all.sh` 以启动 Hadoop集群;

&emsp;&emsp;启动后⽤ `zkServer.sh status` 和 `jps` 命令检查各个服务是否正常启动;

**2.使⽤ HBase Shell连接 HBase：**

&emsp;&emsp;在 **节点 m1**运⾏ `start-hbase.sh` 启动 HBase 服务；

&emsp;&emsp;运⾏ `hbase shell` 进⼊ hbase shell, 接下来关于 hbase的数据操作命令都是在 hbase shell中执⾏。

**3.HBase 操作：**

&emsp;&emsp;创建表 student，设置 2个列簇，分别为 stuinfo 和 course，并显示表结构:

```shell
# 创建表 
create 'student',{NAME=>'stuinfo'},{NAME=>'course'}

#查看表结构
describe 'student' 
``` 

&emsp;&emsp;修改表结构，course 列簇返回最⼤版本数为 3，并显示表结构：

```shell
# 修改表结构
alter 'student',{NAME=>'course',VERSIONS=>3} 

describe 'student'
```

&emsp;&emsp;向列簇中增加列：
```shell
stuinfo 列簇: name,age,sex,dept 
course 列簇: english,math,physics
```
&emsp;&emsp;由于 HBase是采⽤动态添加列，在插⼊数据的同时插⼊列，因此这一步统⼀放在下一步完成。

&emsp;&emsp;向表中添加数据，添加四条学⽣信息:

```shell
put 'student','1','stuinfo:name','laowang' 
put 'student','1','stuinfo:age','18'
put 'student','1','stuinfo:sex','male'
put 'student','1','stuinfo:dept','CS'
put 'student','1','course:english','100' 
put 'student','1','course:math','90'
put 'student','1','course:physics','80'
put 'student','2','stuinfo:name','chris' 
put 'student','2','stuinfo:age','36'
put 'student','2','stuinfo:sex','male' 
put 'student','2','stuinfo:dept','CS' 
put 'student','2','course:english','90' 
put 'student','2','course:math','80'
put 'student','2','course:physics','100'
```

&emsp;&emsp;Note: 由于命令过多且格式相同，故只列出部分命令，都按照 `put 表名, ⾏号, 列簇: 列名, 数据` 
的格式插⼊数据。<p align="center">
    <img src="/pic/2/2-4 学生表.png" width="50%">
    <br/>
    <em>图2-4 学生信息表</em>
</p>

&emsp;&emsp;添加完数据后，⽤ scan 命令查询 student 表中的所有信息：
```shell
# 查询表信息
scan 'student' 
```

&emsp;&emsp;添加完数据后，查询 student 表中指定列簇或列簇中某个列的所有信息：
```shell
# 查询 stuinfo 列簇中的所有信息 
scan 'student', {COLUMN=>'stuinfo'} 

# 查询 stuinfo:sex 列中的所有信息
scan 'student', {COLUMN=>'stuinfo:sex'} 

# 通过 LIMIT 限定查询到的⾏数
scan 'student', {LIMIT=>2, COLUMN=>'stuinfo'} 
```

&emsp;&emsp;更新数据，将 course 列簇中的 english 列的值减 5：
```shell
put 'student','1','course:english','95'
```
&emsp;&emsp;Note：HBase ⽆法统⼀修改数据，只能⼀个个数据重新赋值。

&emsp;&emsp;使⽤ get 查询指定⾏对应列簇或列的信息：
```shell
# 查询第 "1" ⾏ course列簇的信息
get 'student', '1', 'course' 

# 查询第 "1"⾏ course列簇中 english列的信息
get 'student', '1', 'course:english'  

# 查询第 "1"⾏中所有信息
get 'student, '1' 
```

&emsp;&emsp;删除 student 表：
```shell
# 先使表失效，才能删除
disable 'student' 

# 删除表
drop 'student'
```