## 2.1 什么是Hadoop？
&emsp;&emsp;Hadoop 是 Apache 基金会（一个专门支持开源软件项目的非盈利性组织）下的一个开源大数据技术框架，旨在通过分布式集群解决大数据问题，它集成了各种使用程序，如图2-1。其包含三大核心组件，分别是 HDFS、MapReduce 和 YARN，三者个自作用会在后续章节中展开介绍，其他重要组件包括 HBase、Zookeeper、Spark 等，可以说整个大数据技术围绕Hadoop展开。

<p align="center">
    <img src="/pic/2/2-1 Hadoop生态.webp" width="50%">
    <br/>
    <em>图2-1 Hadoop生态</em>
</p>

### 2.1.1 Hadoop的诞生

&emsp;&emsp;Apache Hadoop 开源项目的创建源于工程师 Doug Cutting。2000年3月，Doug Cutting 开源了基于Java的高性能全文检索工具包 Lucene。2002年10月，Doug Cutting 和 Mike Cafarella 创建了基于 Lucene 的开源网页爬虫项目 Nutch。网络搜索引擎和基本文档搜索的区别体现在规模上，Lucene 的目标是索引数百万文档,而 Nutch 目标则是处理数十亿的网页。如此规模的数据使得一台主机无法完成处理，因此，Nutch 面临了一个极大的挑战，即在 Nutch 中建立一个层，来负责分布式处理、冗余、故障恢复及负载均衡等一系列问题——这些问题恰是日后大数据处理框架所具有的优势。Doug Cutting 在Nutch项目中实现了一个分布式文件系统 NDFS 和一个 MapReduce 计算框架。随后这两个模块被单独拿出来，组成一个独立的项目 Hadoop。2005年, Hadoop 正式引入 Apache 基金会。2006年2月,Apache Hadoop 项目正式启动以支持 MapReduce 和 HDFS 的独立发展。2006年4月,第一个 Apache Hadoop 发布。
<p align="center">
    <img src="/pic/2/2-2 Doug Cutting，Hadoop创始人.png" width="50%">
    <br/>
    <em>图2-2 Doug Cutting，Hadoop创始人</em>
</p>


### 2.1.2 什么是HDFS？

&emsp;&emsp;Hadoop 就像是一个用于大数据处理的工具箱，而 HDFS 是里面较为重要的一把螺丝刀，其为整个 Hadoop 生态系统提供底层存储支撑。未经处理的食材存储在其上，待将食材处理成菜肴后也是如此。简单理解，HDFS与 Linux 上的文件系统使用起来并没有很大不同，举例来说，如果我们要在根目录创建一个名叫`hello_bigdata`的文件夹，在 linux 里，我们会写：

&emsp;&emsp;```mkdir /hello_bigdata```

&emsp;&emsp;而在 HDFS 文件系统中，只需这样写：

&emsp;&emsp;```hdfs dfs -mkdir /hello_bigdata```

&emsp;&emsp;其他例如`ls`，`rm`命令也都是如此，他们的操作命令是大致相同的。所以大家无须担心上手一个分布式文件系统有多么困难，只需要你会操作linux文件系统，那么这就不会是一个难事。接下来让我们正式开始学习 HDFS，包括它的主要结构、安装以及使用。
